<?xml version="1.0"?>
<doc>
    <assembly>
        <name>K4AdotNet</name>
    </assembly>
    <members>
        <member name="T:K4AdotNet.BodyTracking.Body">
            <summary>Looks like this structure is unused in current version of Body Tracking SDK.</summary>
        </member>
        <member name="F:K4AdotNet.BodyTracking.Body.Id">
            <summary>An ID for the body that can be used for frame-to-frame correlation.</summary>
        </member>
        <member name="F:K4AdotNet.BodyTracking.Body.Skeleton">
            <summary>The skeleton information for the body.</summary>
        </member>
        <member name="F:K4AdotNet.BodyTracking.BodyId.Invalid">
            <summary>The invalid body id value.</summary>
        </member>
        <member name="T:K4AdotNet.BodyTracking.Joint">
            <summary>Structure to define a single joint.</summary>
            <remarks>
            The position and orientation together defines the coordinate system for the given joint.
            They are defined relative to the sensor global coordinate system.
            </remarks>
        </member>
        <member name="F:K4AdotNet.BodyTracking.Joint.PositionMm">
            <summary>The position of the joint specified in millimeters.</summary>
        </member>
        <member name="F:K4AdotNet.BodyTracking.Joint.Orientation">
            <summary>The orientation of the joint specified in normalized quaternion.</summary>
        </member>
        <member name="T:K4AdotNet.BodyTracking.JointType">
            <summary>Skeleton joint index.</summary>
        </member>
        <member name="T:K4AdotNet.BodyTracking.NativeApi">
            <summary>DLL imports for most of native functions from <c>k4abt.h</c> header file.</summary>
        </member>
        <member name="M:K4AdotNet.BodyTracking.NativeApi.TrackerCreate(K4AdotNet.Sensor.Calibration@,K4AdotNet.NativeHandles.TrackerHandle@)">
            <summary>Create a body tracker handle.</summary>
            <param name="sensorCalibration">The sensor calibration that will be used for capture processing.</param>
            <param name="trackerHandle">Output parameter which on success will return a handle to the body tracker.</param>
            <returns><see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> if the body tracker handle was created successfully.</returns>
        </member>
        <member name="M:K4AdotNet.BodyTracking.NativeApi.TrackerEnqueueCapture(K4AdotNet.NativeHandles.TrackerHandle,K4AdotNet.NativeHandles.CaptureHandle,K4AdotNet.Timeout)">
            <summary>Add a Azure Kinect sensor capture to the tracker input queue to generate its body tracking result asynchronously.</summary>
            <param name="trackerHandle">Handle obtained by <see cref="M:K4AdotNet.BodyTracking.NativeApi.TrackerCreate(K4AdotNet.Sensor.Calibration@,K4AdotNet.NativeHandles.TrackerHandle@)"/>.</param>
            <param name="sensorCaptureHandle">
            Handle to a sensor capture returned by <see cref="M:K4AdotNet.Sensor.NativeApi.CaptureCreate(K4AdotNet.NativeHandles.CaptureHandle@)"/> from Sensor SDK.
            It should contain the depth data for this function to work. Otherwise the function will return failure.
            </param>
            <param name="timeout">
            Specifies the time the function should block waiting to add the sensor capture to the tracker
            process queue. <see cref="F:K4AdotNet.Timeout.NoWait"/> is a check of the status without blocking.
            Passing <see cref="F:K4AdotNet.Timeout.Infinite"/> will block indefinitely until the capture is added to the process queue.
            </param>
            <returns>
            <see cref="F:K4AdotNet.NativeCallResults.WaitResult.Succeeded"/> if a sensor capture is successfully added to the processing queue. If the queue is still
            full before the timeout elapses, the function will return <see cref="F:K4AdotNet.NativeCallResults.WaitResult.Timeout"/>. All other failures will return
            <see cref="F:K4AdotNet.NativeCallResults.WaitResult.Failed"/>.
            </returns>
            <remarks>
            Add a Azure Kinect capture to the tracker input queue so that it can be processed asynchronously to generate the body tracking
            result. The processed results will be added to an output queue maintained by <see cref="T:K4AdotNet.NativeHandles.TrackerHandle"/> instance. Call
            <see cref="M:K4AdotNet.BodyTracking.NativeApi.TrackerPopResult(K4AdotNet.NativeHandles.TrackerHandle,K4AdotNet.NativeHandles.BodyFrameHandle@,K4AdotNet.Timeout)"/> to get the result and pop it from the output queue.
            If the input queue or output queue is full, this function will block up until the timeout is reached.
            
            Upon successfully insert a sensor capture to the input queue this function will return success.
            
            This function returns <see cref="F:K4AdotNet.NativeCallResults.WaitResult.Failed"/> when either the tracker is shut down by <see cref="M:K4AdotNet.BodyTracking.NativeApi.TrackerShutdown(K4AdotNet.NativeHandles.TrackerHandle)"/> API,
            or an internal problem is encountered before adding to the input queue: such as low memory condition,
            <paramref name="sensorCaptureHandle"/> not containing the depth data, or other unexpected issues.
            </remarks>
        </member>
        <member name="M:K4AdotNet.BodyTracking.NativeApi.TrackerPopResult(K4AdotNet.NativeHandles.TrackerHandle,K4AdotNet.NativeHandles.BodyFrameHandle@,K4AdotNet.Timeout)">
            <summary>Gets the next available body frame.</summary>
            <param name="trackerHandle">Handle obtained by <see cref="M:K4AdotNet.BodyTracking.NativeApi.TrackerCreate(K4AdotNet.Sensor.Calibration@,K4AdotNet.NativeHandles.TrackerHandle@)"/>.</param>
            <param name="bodyFrameHandle">If successful this contains a handle to a body frame object.</param>
            <param name="timeout">
            Specifies the time the function should block waiting for the body frame. <see cref="F:K4AdotNet.Timeout.NoWait"/> is a check of the status without blocking.
            Passing <see cref="F:K4AdotNet.Timeout.Infinite"/> will block indefinitely until the body frame becomes available.
            </param>
            <returns>
            <see cref="F:K4AdotNet.NativeCallResults.WaitResult.Succeeded"/> if a body frame is returned. If a body frame is not available before the timeout elapses,
            the function will return <see cref="F:K4AdotNet.NativeCallResults.WaitResult.Timeout"/>. All other failures will return <see cref="F:K4AdotNet.NativeCallResults.WaitResult.Failed"/>.
            </returns>
            <remarks>
            Retrieves the next available body frame result and pop it from the output queue in the <see cref="T:K4AdotNet.NativeHandles.TrackerHandle"/>.
            If a new body frame is not currently available, this function will block up until the timeout is reached.
            The SDK will buffer at least three body frames worth of data before stopping new capture being queued by <see cref="M:K4AdotNet.BodyTracking.NativeApi.TrackerEnqueueCapture(K4AdotNet.NativeHandles.TrackerHandle,K4AdotNet.NativeHandles.CaptureHandle,K4AdotNet.Timeout)"/>.
            
            Upon successfully reads a body frame this function will return success.
            
            This function returns <see cref="F:K4AdotNet.NativeCallResults.WaitResult.Failed"/> when either the tracker is shut down by <see cref="M:K4AdotNet.BodyTracking.NativeApi.TrackerShutdown(K4AdotNet.NativeHandles.TrackerHandle)"/> API
            and the remaining tracker queue is empty, or an internal problem is encountered: such as low memory condition, or
            other unexpected issues.
            </remarks>
        </member>
        <member name="M:K4AdotNet.BodyTracking.NativeApi.TrackerShutdown(K4AdotNet.NativeHandles.TrackerHandle)">
             <summary>Shutdown the tracker so that no further capture can be added to the input queue.</summary>
             <param name="trackerHandle">Handle obtained by <see cref="M:K4AdotNet.BodyTracking.NativeApi.TrackerCreate(K4AdotNet.Sensor.Calibration@,K4AdotNet.NativeHandles.TrackerHandle@)"/>.</param>
             <remarks>
             Once the tracker is shutdown, <see cref="M:K4AdotNet.BodyTracking.NativeApi.TrackerEnqueueCapture(K4AdotNet.NativeHandles.TrackerHandle,K4AdotNet.NativeHandles.CaptureHandle,K4AdotNet.Timeout)"/> API will always immediately return failure.
            
             If there are remaining captures in the tracker queue after the tracker is shutdown, <see cref="M:K4AdotNet.BodyTracking.NativeApi.TrackerPopResult(K4AdotNet.NativeHandles.TrackerHandle,K4AdotNet.NativeHandles.BodyFrameHandle@,K4AdotNet.Timeout)"/> can
             still return successfully. Once the tracker queue is empty, the <see cref="M:K4AdotNet.BodyTracking.NativeApi.TrackerPopResult(K4AdotNet.NativeHandles.TrackerHandle,K4AdotNet.NativeHandles.BodyFrameHandle@,K4AdotNet.Timeout)"/> call will always immediately
             return failure.
             </remarks>
        </member>
        <member name="M:K4AdotNet.BodyTracking.NativeApi.FrameGetNumBodies(K4AdotNet.NativeHandles.BodyFrameHandle)">
            <summary>Get the number of people from the <see cref="T:K4AdotNet.NativeHandles.BodyFrameHandle"/>.</summary>
            <param name="bodyFrameHandle">Handle to a body frame object returned by <see cref="M:K4AdotNet.BodyTracking.NativeApi.TrackerPopResult(K4AdotNet.NativeHandles.TrackerHandle,K4AdotNet.NativeHandles.BodyFrameHandle@,K4AdotNet.Timeout)"/> function.</param>
            <returns>Returns the number of detected bodies. 0 if the function fails.</returns>
            <remarks>Called when the user has received a body frame handle and wants to access the data contained in it.</remarks>
        </member>
        <member name="M:K4AdotNet.BodyTracking.NativeApi.FrameGetBodySkeleton(K4AdotNet.NativeHandles.BodyFrameHandle,System.UIntPtr,K4AdotNet.BodyTracking.Skeleton@)">
            <summary>Get the joint information for a particular person index from the <see cref="T:K4AdotNet.NativeHandles.BodyFrameHandle"/>.</summary>
            <param name="bodyFrameHandle">Handle to a body frame object returned by <see cref="M:K4AdotNet.BodyTracking.NativeApi.TrackerPopResult(K4AdotNet.NativeHandles.TrackerHandle,K4AdotNet.NativeHandles.BodyFrameHandle@,K4AdotNet.Timeout)"/> function.</param>
            <param name="index">The index of the body of which the joint information is queried.</param>
            <param name="skeleton">If successful this contains the body skeleton information.</param>
            <returns><see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> if a valid body skeleton is returned. All failures will return <see cref="F:K4AdotNet.NativeCallResults.Result.Failed"/>.</returns>
            <remarks>Called when the user has received a body frame handle and wants to access the data contained in it.</remarks>
        </member>
        <member name="M:K4AdotNet.BodyTracking.NativeApi.FrameGetBodyId(K4AdotNet.NativeHandles.BodyFrameHandle,System.UIntPtr)">
            <summary>Get the body id for a particular person index from the <see cref="T:K4AdotNet.NativeHandles.BodyFrameHandle"/>.</summary>
            <param name="bodyFrameHandle">Handle to a body frame object returned by <see cref="M:K4AdotNet.BodyTracking.NativeApi.TrackerPopResult(K4AdotNet.NativeHandles.TrackerHandle,K4AdotNet.NativeHandles.BodyFrameHandle@,K4AdotNet.Timeout)"/> function.</param>
            <param name="index">The index of the body of which the body id information is queried.</param>
            <returns>Returns the body id. All failures will return <see cref="F:K4AdotNet.BodyTracking.BodyId.Invalid"/>.</returns>
            <remarks>
            Called when the user has received a body frame handle and wants to access the id of the body given a particular index.
            </remarks>
        </member>
        <member name="M:K4AdotNet.BodyTracking.NativeApi.FrameGetTimestamp(K4AdotNet.NativeHandles.BodyFrameHandle)">
            <summary>Get the body frame timestamp.</summary>
            <param name="bodyFrameHandle">Handle to a body frame object returned by <see cref="M:K4AdotNet.BodyTracking.NativeApi.TrackerPopResult(K4AdotNet.NativeHandles.TrackerHandle,K4AdotNet.NativeHandles.BodyFrameHandle@,K4AdotNet.Timeout)"/> function.</param>
            <returns>
            Returns the timestamp of the body frame. If the <paramref name="bodyFrameHandle"/> is invalid this function will return <see cref="F:K4AdotNet.Microseconds64.Zero"/>.
            It is also possible for <see cref="F:K4AdotNet.Microseconds64.Zero"/> to be a valid timestamp originating from the beginning of a recording or the start of streaming.
            </returns>
        </member>
        <member name="M:K4AdotNet.BodyTracking.NativeApi.FrameGetBodyIndexMap(K4AdotNet.NativeHandles.BodyFrameHandle)">
            <summary>Get the body index map from <see cref="T:K4AdotNet.NativeHandles.BodyFrameHandle"/>.</summary>
            <param name="bodyFrameHandle">Handle to a body frame object returned by <see cref="M:K4AdotNet.BodyTracking.NativeApi.TrackerPopResult(K4AdotNet.NativeHandles.TrackerHandle,K4AdotNet.NativeHandles.BodyFrameHandle@,K4AdotNet.Timeout)"/> function.</param>
            <returns>Call this function to access the body index map image. Don't forget to call <see cref="M:System.IDisposable.Dispose"/> for returned handle after usage.</returns>
            <remarks>
            Called when the user has received a body frame handle and wants to access the data contained in it.
            
            Body Index map is the body instance segmentation map. Each pixel maps to the corresponding pixel in the
            depth image or the IR image. The value for each pixel represents which body the pixel belongs to. It can be either
            background (value <c>0xFF</c>) or the index of a detected <see cref="T:K4AdotNet.BodyTracking.Body"/>.
            </remarks>
        </member>
        <member name="M:K4AdotNet.BodyTracking.NativeApi.FrameGetCapture(K4AdotNet.NativeHandles.BodyFrameHandle)">
            <summary>Get the original capture that is used to calculate <see cref="T:K4AdotNet.NativeHandles.BodyFrameHandle"/>.</summary>
            <param name="bodyFrameHandle">Handle to a body frame object returned by <see cref="M:K4AdotNet.BodyTracking.NativeApi.TrackerPopResult(K4AdotNet.NativeHandles.TrackerHandle,K4AdotNet.NativeHandles.BodyFrameHandle@,K4AdotNet.Timeout)"/> function.</param>
            <returns>Call this function to access the original <see cref="T:K4AdotNet.NativeHandles.CaptureHandle"/>. Don't forget to call <see cref="M:System.IDisposable.Dispose"/> for returned handle after usage.</returns>
            <remarks>
            Called when the user has received a body frame handle and wants to access the data contained in it.
            </remarks>
        </member>
        <member name="T:K4AdotNet.BodyTracking.Skeleton">
            <summary>Structure to define joints for skeleton.</summary>
        </member>
        <member name="T:K4AdotNet.Float2">
            <summary>Two dimensional floating point vector.</summary>
        </member>
        <member name="F:K4AdotNet.Float2.X">
            <summary>X component of a vector. Corresponds to <c>0</c> index in array representation.</summary>
        </member>
        <member name="F:K4AdotNet.Float2.Y">
            <summary>Y component of a vector. Corresponds to <c>1</c> index in array representation.</summary>
        </member>
        <member name="M:K4AdotNet.Float2.#ctor(System.Single,System.Single)">
            <summary>Constructs vector with given components.</summary>
            <param name="x">X component</param>
            <param name="y">Y component</param>
        </member>
        <member name="P:K4AdotNet.Float2.Item(System.Int32)">
            <summary>Indexed access to vector components.</summary>
            <param name="index">Index of component: <c>X</c> - <c>0</c>, <c>Y</c> - <c>1</c>.</param>
            <returns>Value of appropriate component.</returns>
        </member>
        <member name="M:K4AdotNet.Float2.Equals(K4AdotNet.Float2)">
            <summary>Per-component comparison.</summary>
            <param name="other">Other vector to be compared to this one.</param>
            <returns><c>true</c> if all components are equal.</returns>
        </member>
        <member name="M:K4AdotNet.Float2.ToString(System.String,System.IFormatProvider)">
            <summary>Formats vector as <c>[X Y]</c> string.</summary>
            <param name="format">Format string for each individual component in string representation.</param>
            <param name="formatProvider">Culture for formatting numbers to strings.</param>
            <returns>String representation of vector in a given Culture.</returns>
        </member>
        <member name="F:K4AdotNet.Float2.Zero">
            <summary>Zero vector.</summary>
        </member>
        <member name="F:K4AdotNet.Float2.UnitX">
            <summary>Unit vector in +X direction.</summary>
        </member>
        <member name="F:K4AdotNet.Float2.UnitY">
            <summary>Unit vector in +Y direction.</summary>
        </member>
        <member name="T:K4AdotNet.Float3">
            <summary>X, Y, Z representation of a vector.</summary>
        </member>
        <member name="F:K4AdotNet.Float3.X">
            <summary>X component of a vector. Corresponds to <c>0</c> index in array representation.</summary>
        </member>
        <member name="F:K4AdotNet.Float3.Y">
            <summary>Y component of a vector. Corresponds to <c>1</c> index in array representation.</summary>
        </member>
        <member name="F:K4AdotNet.Float3.Z">
            <summary>Z component of a vector. Corresponds to <c>2</c> index in array representation.</summary>
        </member>
        <member name="M:K4AdotNet.Float3.#ctor(System.Single,System.Single,System.Single)">
            <summary>Constructs vector with given components.</summary>
            <param name="x">X component</param>
            <param name="y">Y component</param>
            <param name="z">Z component</param>
        </member>
        <member name="P:K4AdotNet.Float3.Item(System.Int32)">
            <summary>Indexed access to vector components.</summary>
            <param name="index">Index of component: <c>X</c> - <c>0</c>, <c>Y</c> - <c>1</c>, <c>Z</c> - <c>2</c>.</param>
            <returns>Value of appropriate component.</returns>
        </member>
        <member name="M:K4AdotNet.Float3.Equals(K4AdotNet.Float3)">
            <summary>Per-component comparison.</summary>
            <param name="other">Other vector to be compared to this one.</param>
            <returns><c>true</c> if all components are equal.</returns>
        </member>
        <member name="M:K4AdotNet.Float3.ToString(System.String,System.IFormatProvider)">
            <summary>Formats vector as <c>[X Y Z]</c> string.</summary>
            <param name="format">Format string for each individual component in string representation.</param>
            <param name="formatProvider">Culture for formatting numbers to strings.</param>
            <returns>String representation of vector in a given Culture.</returns>
        </member>
        <member name="F:K4AdotNet.Float3.Zero">
            <summary>Zero vector.</summary>
        </member>
        <member name="F:K4AdotNet.Float3.UnitX">
            <summary>Unit vector in +X direction.</summary>
        </member>
        <member name="F:K4AdotNet.Float3.UnitY">
            <summary>Unit vector in +Y direction.</summary>
        </member>
        <member name="F:K4AdotNet.Float3.UnitZ">
            <summary>Unit vector in +Z direction.</summary>
        </member>
        <member name="T:K4AdotNet.Float3x3">
            <summary>Placeholder for 3x3 matrix data.</summary>
        </member>
        <member name="T:K4AdotNet.NativeCallResults.BufferResult">
            <summary>Result code returned by Azure Kinect APIs.</summary>
        </member>
        <member name="F:K4AdotNet.NativeCallResults.BufferResult.Succeeded">
            <summary>The result was successful</summary>
        </member>
        <member name="F:K4AdotNet.NativeCallResults.BufferResult.Failed">
            <summary>The result was a failure</summary>
        </member>
        <member name="F:K4AdotNet.NativeCallResults.BufferResult.TooSmall">
            <summary>The input buffer was too small</summary>
        </member>
        <member name="T:K4AdotNet.NativeCallResults.Result">
            <summary>Result code returned by Azure Kinect APIs.</summary>
        </member>
        <member name="F:K4AdotNet.NativeCallResults.Result.Succeeded">
            <summary>The result was successful</summary>
        </member>
        <member name="F:K4AdotNet.NativeCallResults.Result.Failed">
            <summary>The result was a failure</summary>
        </member>
        <member name="T:K4AdotNet.NativeCallResults.StreamResult">
            <summary>Return codes returned by Azure Kinect playback API.</summary>
        </member>
        <member name="F:K4AdotNet.NativeCallResults.StreamResult.Succeeded">
            <summary>The result was successful</summary>
        </member>
        <member name="F:K4AdotNet.NativeCallResults.StreamResult.Failed">
            <summary>The result was a failure</summary>
        </member>
        <member name="F:K4AdotNet.NativeCallResults.StreamResult.Eof">
            <summary>The end of the data stream was reached</summary>
        </member>
        <member name="T:K4AdotNet.NativeCallResults.WaitResult">
            <summary>Result code returned by Azure Kinect APIs.</summary>
        </member>
        <member name="F:K4AdotNet.NativeCallResults.WaitResult.Succeeded">
            <summary>The result was successful</summary>
        </member>
        <member name="F:K4AdotNet.NativeCallResults.WaitResult.Failed">
            <summary>The result was a failure</summary>
        </member>
        <member name="F:K4AdotNet.NativeCallResults.WaitResult.Timeout">
            <summary>The operation timed out</summary>
        </member>
        <member name="T:K4AdotNet.NativeHandles.BodyFrameHandle">
            <summary>Handle to an Azure Kinect body tracking frame.</summary>
        </member>
        <member name="M:K4AdotNet.NativeHandles.BodyFrameHandle.DuplicateReference">
            <summary>Call this method if you want to have one more reference to the same body frame.</summary>
            <returns>Additional reference to the same body frame. Don't forget to call <see cref="M:System.IDisposable.Dispose"/> method for object returned.</returns>
        </member>
        <member name="T:K4AdotNet.NativeHandles.CaptureHandle">
            <summary>Handle to an Azure Kinect capture.</summary>
            <remarks>
            Empty captures are created with <c>k4a_capture_create()</c>.
            Captures can be obtained from a device using <c>k4a_device_get_capture()</c>.
            </remarks>
        </member>
        <member name="M:K4AdotNet.NativeHandles.CaptureHandle.DuplicateReference">
            <summary>
            Call this method if you want to have one more reference to the same capture.
            </summary>
            <returns>Additional reference to the same capture. Don't forget to call <see cref="M:System.IDisposable.Dispose"/> method for object returned.</returns>
        </member>
        <member name="T:K4AdotNet.NativeHandles.DeviceHandle">
            <summary>Handle to an Azure Kinect device.</summary>
        </member>
        <member name="T:K4AdotNet.NativeHandles.HandleBase">
            <summary>Base class for all native handles declared it Sensor SDK.</summary>
            <remarks>
            Handles represent object instances in Sensor SDK.
            Handles are opaque pointers returned by the SDK which represent an object.
            Invalid handles are set to 0 (<c>IntPtr.Zero</c>).
            </remarks>
        </member>
        <member name="M:K4AdotNet.NativeHandles.HandleBase.#ctor">
            <summary>Instances always own handles they store.</summary>
        </member>
        <member name="P:K4AdotNet.NativeHandles.HandleBase.IsInvalid">
            <summary>Invalid handle is <c>IntPtr.Zero</c>.</summary>
        </member>
        <member name="T:K4AdotNet.NativeHandles.ImageHandle">
            <summary>Handle to an Azure Kinect image.</summary>
            <remarks>Images from a device are retrieved through a <c>k4a_capture_t</c> object returned by <c>k4a_device_get_capture()</c>.</remarks>
        </member>
        <member name="M:K4AdotNet.NativeHandles.ImageHandle.DuplicateReference">
            <summary>Call this method if you want to have one more reference to the same image.</summary>
            <returns>Additional reference to the same image. Don't forget to call <see cref="M:System.IDisposable.Dispose"/> method for object returned.</returns>
        </member>
        <member name="T:K4AdotNet.NativeHandles.NativeApi">
            <summary>DLL imports of some native functions from <c>k4a.h</c>, <c>record.h</c>, <c>playback.h</c> and <c>k4abt.h</c> header files.</summary>
            <remarks>These functions are required for implementation of Handle classes.</remarks>
        </member>
        <member name="M:K4AdotNet.NativeHandles.NativeApi.CaptureReference(System.IntPtr)">
            <summary>Add a reference to a capture.</summary>
            <param name="captureHandle">Capture to add a reference to.</param>
            <remarks>Call this function to add an additional reference to a capture.
                This reference must be removed with <see cref="M:K4AdotNet.NativeHandles.NativeApi.CaptureReference(System.IntPtr)"/>.</remarks>
        </member>
        <member name="M:K4AdotNet.NativeHandles.NativeApi.CaptureRelease(System.IntPtr)">
            <summary>Release a capture.</summary>
            <param name="captureHandle">Capture to release.</param>
        </member>
        <member name="M:K4AdotNet.NativeHandles.NativeApi.ImageReference(System.IntPtr)">
            <summary>Add a reference to the image.</summary>
            <param name="imageHandle">Handle of the image for which the get operation is performed on.</param>
            <remarks>
            References manage the lifetime of the object. When the references reach zero the object is destroyed. A caller must
            not access the object after its reference is released.
            </remarks>
        </member>
        <member name="M:K4AdotNet.NativeHandles.NativeApi.ImageRelease(System.IntPtr)">
            <summary>Remove a reference from the image.</summary>
            <param name="imageHandle">Handle of the image for which the get operation is performed on.</param>
            <remarks>
            References manage the lifetime of the object. When the references reach zero the object is destroyed. A caller must
            not access the object after its reference is released.
            </remarks>
        </member>
        <member name="M:K4AdotNet.NativeHandles.NativeApi.TransformationDestroy(System.IntPtr)">
            <summary>Destroy transformation handle.</summary>
            <param name="transformationHandle">Transformation handle to destroy.</param>
        </member>
        <member name="M:K4AdotNet.NativeHandles.NativeApi.DeviceClose(System.IntPtr)">
            <summary>Closes an Azure Kinect device.</summary>
            <param name="deviceHandle">Handle of device for which the get operation is performed on.</param>
            <remarks>Once closed, the handle is no longer valid.</remarks>
        </member>
        <member name="M:K4AdotNet.NativeHandles.NativeApi.TrackerDestroy(System.IntPtr)">
            <summary>Releases a body tracker handle. </summary>
            <param name="trackerHandle">Tracker to be destroyed.</param>
            <remarks>Once destroyed, the handle is no longer valid.</remarks>
        </member>
        <member name="M:K4AdotNet.NativeHandles.NativeApi.FrameRelease(System.IntPtr)">
            <summary>Release a body frame back to the SDK.</summary>
            <param name="bodyFrameHandle">Handle to a body frame object to return to SDK.</param>
            <remarks>Once released, the handle is no longer valid.</remarks>
        </member>
        <member name="M:K4AdotNet.NativeHandles.NativeApi.FrameReference(System.IntPtr)">
            <summary>Add a reference to a body frame.</summary>
            <param name="bodyFrameHandle">Body frame to add a reference to.</param>
            <remarks>Call this function to add an additional reference to a body frame.</remarks>
        </member>
        <member name="M:K4AdotNet.NativeHandles.NativeApi.RecordClose(System.IntPtr)">
            <summary>Closes a recording handle.</summary>
            <param name="recordingHandle">Recording handle to be closed.</param>
            <remarks>If there is any unwritten data it will be flushed to disk before closing the recording.</remarks>
        </member>
        <member name="M:K4AdotNet.NativeHandles.NativeApi.PlaybackClose(System.IntPtr)">
            <summary>Closes a recording playback handle.</summary>
            <param name="recordingHandle">Recording playback handle to be closed.</param>
        </member>
        <member name="T:K4AdotNet.NativeHandles.PlaybackHandle">
            <summary>Handle to a Kinect for Azure recording opened for playback.</summary>
        </member>
        <member name="T:K4AdotNet.NativeHandles.RecordHandle">
            <summary>Handle to a Kinect for Azure recording opened for writing.</summary>
        </member>
        <member name="T:K4AdotNet.NativeHandles.TrackerHandle">
            <summary>Handle to Azure Kinect body tracking component.</summary>
        </member>
        <member name="T:K4AdotNet.NativeHandles.TransformationHandle">
            <summary>Handle to an Azure Kinect transformation context.</summary>
            <remarks>Handles are created with <c>k4a_transformation_create()</c>.</remarks>
        </member>
        <member name="T:K4AdotNet.Quaternion">
            <summary>WXYZ representation of quaternion.</summary>
        </member>
        <member name="F:K4AdotNet.Quaternion.W">
            <summary>W component of a vector. Corresponds to <c>0</c> index in array representation.</summary>
        </member>
        <member name="F:K4AdotNet.Quaternion.X">
            <summary>X component of a vector. Corresponds to <c>1</c> index in array representation.</summary>
        </member>
        <member name="F:K4AdotNet.Quaternion.Y">
            <summary>Y component of a vector. Corresponds to <c>2</c> index in array representation.</summary>
        </member>
        <member name="F:K4AdotNet.Quaternion.Z">
            <summary>Z component of a vector. Corresponds to <c>3</c> index in array representation.</summary>
        </member>
        <member name="T:K4AdotNet.Record.NativeApi">
            <summary>DLL imports for most of native functions from <c>record.h</c> and <c>playback.h</c> header files.</summary>
        </member>
        <member name="M:K4AdotNet.Record.NativeApi.RecordCreate(System.Byte[],K4AdotNet.NativeHandles.DeviceHandle,K4AdotNet.Sensor.DeviceConfiguration,K4AdotNet.NativeHandles.RecordHandle@)">
            <summary>
            Opens a new recording file for writing.
            The file will be created if it doesn't exist, or overwritten if an existing file is specified.
            </summary>
            <param name="path">File system path for the new recording.</param>
            <param name="device">The Azure Kinect device that is being recorded. The device handle is used to store device calibration and serial
            number information. May be <see cref="F:K4AdotNet.NativeHandles.DeviceHandle.Zero"/> if recording user-generated data.</param>
            <param name="deviceConfiguration">The configuration the Azure Kinect device was started with.</param>
            <param name="recordingHandle">If successful, this contains a pointer to the new recording handle.</param>
            <returns><see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> is returned on success.</returns>
            <remarks>
            Streaming does not need to be started on the device at the time this function is called, but when it is started
            it should be started with the same configuration provided in <paramref name="deviceConfiguration"/>.
            
            Subsequent calls to <see cref="M:K4AdotNet.Record.NativeApi.RecordWriteCapture(K4AdotNet.NativeHandles.RecordHandle,K4AdotNet.NativeHandles.CaptureHandle)"/> will need to have images in the resolution and format defined
            in <paramref name="deviceConfiguration"/>.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Record.NativeApi.RecordAddTag(K4AdotNet.NativeHandles.RecordHandle,System.Byte[],System.Byte[])">
            <summary>Adds a tag to the recording. All tags need to be added before the recording header is written.</summary>
            <param name="recordingHandle">The handle of a new recording, obtained by <see cref="M:K4AdotNet.Record.NativeApi.RecordCreate(System.Byte[],K4AdotNet.NativeHandles.DeviceHandle,K4AdotNet.Sensor.DeviceConfiguration,K4AdotNet.NativeHandles.RecordHandle@)"/>.</param>
            <param name="name">The name of the tag to write.</param>
            <param name="value">The string value to store in the tag.</param>
            <returns><see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> is returned on success.</returns>
            <remarks>
            Tags are global to a file, and should store data related to the entire recording, such as camera configuration or
            recording location.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Record.NativeApi.RecordAddImuTrack(K4AdotNet.NativeHandles.RecordHandle)">
            <summary>Adds the track header for recording IMU. The track needs to be added before the recording header is written.</summary>
            <param name="recordingHandle">The handle of a new recording, obtained by <see cref="M:K4AdotNet.Record.NativeApi.RecordCreate(System.Byte[],K4AdotNet.NativeHandles.DeviceHandle,K4AdotNet.Sensor.DeviceConfiguration,K4AdotNet.NativeHandles.RecordHandle@)"/>.</param>
            <returns><see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> is returned on success.</returns>
        </member>
        <member name="M:K4AdotNet.Record.NativeApi.RecordWriteHeader(K4AdotNet.NativeHandles.RecordHandle)">
            <summary>Writes the recording header and metadata to file. This must be called before captures can be written.</summary>
            <param name="recordingHandle">The handle of a new recording, obtained by <see cref="M:K4AdotNet.Record.NativeApi.RecordCreate(System.Byte[],K4AdotNet.NativeHandles.DeviceHandle,K4AdotNet.Sensor.DeviceConfiguration,K4AdotNet.NativeHandles.RecordHandle@)"/>.</param>
            <returns><see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> is returned on success.</returns>
        </member>
        <member name="M:K4AdotNet.Record.NativeApi.RecordWriteCapture(K4AdotNet.NativeHandles.RecordHandle,K4AdotNet.NativeHandles.CaptureHandle)">
            <summary>
            Writes a camera capture to file.
            Captures must be written in increasing order of timestamp, and the file's header must already be written.
            </summary>
            <param name="recordingHandle">The handle of recording, obtained by <see cref="M:K4AdotNet.Record.NativeApi.RecordCreate(System.Byte[],K4AdotNet.NativeHandles.DeviceHandle,K4AdotNet.Sensor.DeviceConfiguration,K4AdotNet.NativeHandles.RecordHandle@)"/>.</param>
            <param name="captureHandle">The handle of a capture to write to file.</param>
            <returns><see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> is returned on success.</returns>
            <remarks>
            This method will write all images in the capture to the corresponding tracks in the recording file.
            If any of the images fail to write, other images will still be written before a failure is returned.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Record.NativeApi.RecordWriteImuSample(K4AdotNet.NativeHandles.RecordHandle,K4AdotNet.Sensor.ImuSample)">
            <summary>Writes an IMU sample to file.</summary>
            <param name="recordingHandle">The handle of recording, obtained by <see cref="M:K4AdotNet.Record.NativeApi.RecordCreate(System.Byte[],K4AdotNet.NativeHandles.DeviceHandle,K4AdotNet.Sensor.DeviceConfiguration,K4AdotNet.NativeHandles.RecordHandle@)"/>.</param>
            <param name="imuSample">A structure containing the IMU sample data and time stamps.</param>
            <returns><see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> is returned on success.</returns>
            <remarks>
            Samples must be written in increasing order of timestamp, and the file's header must already be written.
            When writing IMU samples at the same time as captures, the samples should be within 1 second of the most recently
            written capture.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Record.NativeApi.RecordFlush(K4AdotNet.NativeHandles.RecordHandle)">
            <summary>Flushes all pending recording data to disk.</summary>
            <param name="recordingHandle">The handle of recording, obtained by <see cref="M:K4AdotNet.Record.NativeApi.RecordCreate(System.Byte[],K4AdotNet.NativeHandles.DeviceHandle,K4AdotNet.Sensor.DeviceConfiguration,K4AdotNet.NativeHandles.RecordHandle@)"/>.</param>
            <returns><see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> is returned on success.</returns>
            <remarks>
            This method ensures that all data passed to the recording API prior to calling flush is written to disk.
            If continuing to write recording data, care must be taken to ensure no new time stamps are added from before the flush.
            
            If an error occurs, best effort is made to flush as much data to disk as possible, but the integrity of the file is
            not guaranteed.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Record.NativeApi.PlaybackOpen(System.Byte[],K4AdotNet.NativeHandles.PlaybackHandle@)">
            <summary>Opens an existing recording file for reading.</summary>
            <param name="path">File system path of the existing recording.</param>
            <param name="playbackHandle">If successful, this contains a pointer to the recording handle.</param>
            <returns><see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> is returned on success.</returns>
        </member>
        <member name="M:K4AdotNet.Record.NativeApi.PlaybackGetRawCalibration(K4AdotNet.NativeHandles.PlaybackHandle,System.Byte[],System.UIntPtr@)">
            <summary>Get the raw calibration blob for the Azure Kinect device used during recording.</summary>
            <param name="playbackHandle">Handle obtained by <see cref="M:K4AdotNet.Record.NativeApi.PlaybackOpen(System.Byte[],K4AdotNet.NativeHandles.PlaybackHandle@)"/>.</param>
            <param name="data">
            Location to write the calibration data to. This field may optionally be set to <see langword="null"/>
            if the caller wants to query for the needed data size.
            </param>
            <param name="dataSize">
            On passing <paramref name="dataSize"/> into the function this variable represents the available size to write the raw data to. On
            return this variable is updated with the amount of data actually written to the buffer.
            </param>
            <returns>
            <see cref="F:K4AdotNet.NativeCallResults.BufferResult.Succeeded"/> if <paramref name="data"/> was successfully written.
            If <paramref name="dataSize"/> points to a buffer size that is too small to hold the output,
            <see cref="F:K4AdotNet.NativeCallResults.BufferResult.TooSmall"/> is returned and <paramref name="dataSize"/> is updated to contain the
            minimum buffer size needed to capture the calibration data.
            </returns>
            <remarks>The raw calibration may not exist if the device was not specified during recording.</remarks>
        </member>
        <member name="M:K4AdotNet.Record.NativeApi.PlaybackGetCalibration(K4AdotNet.NativeHandles.PlaybackHandle,K4AdotNet.Sensor.Calibration@)">
            <summary>
            Get the camera calibration for Azure Kinect device used during recording.
            The output struct is used as input to all transformation functions.
            </summary>
            <param name="playbackHandle">Handle obtained by <see cref="M:K4AdotNet.Record.NativeApi.PlaybackOpen(System.Byte[],K4AdotNet.NativeHandles.PlaybackHandle@)"/>.</param>
            <param name="calibration">Output: calibration data.</param>
            <returns><see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> is returned on success.</returns>
            <remarks>The calibration may not exist if the device was not specified during recording.</remarks>
        </member>
        <member name="M:K4AdotNet.Record.NativeApi.PlaybackGetRecordConfiguration(K4AdotNet.NativeHandles.PlaybackHandle,K4AdotNet.Record.RecordConfiguration@)">
            <summary>Get the device configuration used during recording.</summary>
            <param name="playbackHandle">Handle obtained by <see cref="M:K4AdotNet.Record.NativeApi.PlaybackOpen(System.Byte[],K4AdotNet.NativeHandles.PlaybackHandle@)"/>.</param>
            <param name="config">Output: recording configuration.</param>
            <returns><see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> if <paramref name="config"/> was successfully written. <see cref="F:K4AdotNet.NativeCallResults.Result.Failed"/> otherwise.</returns>
        </member>
        <member name="M:K4AdotNet.Record.NativeApi.PlaybackGetTag(K4AdotNet.NativeHandles.PlaybackHandle,System.Byte[],System.Byte[],System.UIntPtr@)">
            <summary>Read the value of a tag from a recording.</summary>
            <param name="playbackHandle">Handle obtained by <see cref="M:K4AdotNet.Record.NativeApi.PlaybackOpen(System.Byte[],K4AdotNet.NativeHandles.PlaybackHandle@)"/>.</param>
            <param name="name">The name of the tag to read.</param>
            <param name="value">
            Location to write the tag value. If a <see langword="null"/> buffer is specified,
            <paramref name="valueSize"/> will be set to the size of buffer needed to store the string.
            </param>
            <param name="valueSize">
            On input, the size of the <paramref name="value"/> buffer. On output, this is set to the length of the tag value (including the null
            terminator).
            </param>
            <returns>
            A return of <see cref="F:K4AdotNet.NativeCallResults.BufferResult.Succeeded"/> means that the <paramref name="value"/> has been filled in.
            If the buffer is too small the function returns <see cref="F:K4AdotNet.NativeCallResults.BufferResult.TooSmall"/> and the needed size of the <paramref name="value"/>
            buffer is returned in the <paramref name="valueSize"/> parameter.
            <see cref="F:K4AdotNet.NativeCallResults.BufferResult.Failed"/> is returned if the tag does not exist.
            All other failures return <see cref="F:K4AdotNet.NativeCallResults.BufferResult.Failed"/>.
            </returns>
            <remarks>
            Tags are global to a file, and should store data related to the entire recording, such as camera configuration or
            recording location.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Record.NativeApi.PlaybackSetColorConversion(K4AdotNet.NativeHandles.PlaybackHandle,K4AdotNet.Sensor.ImageFormat)">
            <summary>
            Set the image format that color captures will be converted to. By default the conversion format will be the same as
            the image format stored in the recording file, and no conversion will occur.
            </summary>
            <param name="playbackHandle">Handle obtained by <see cref="M:K4AdotNet.Record.NativeApi.PlaybackOpen(System.Byte[],K4AdotNet.NativeHandles.PlaybackHandle@)"/>.</param>
            <param name="targetFormat">The target image format to be returned in captures.</param>
            <returns><see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> if the format conversion is supported. <see cref="F:K4AdotNet.NativeCallResults.Result.Failed"/> otherwise.</returns>
            <remarks>
            After the color conversion format is set, all <see cref="T:K4AdotNet.NativeHandles.CaptureHandle"/> objects returned from the playback handle will have
            their color images converted to the <paramref name="targetFormat"/>.
            
            Color format conversion occurs in the user-thread, so setting <paramref name="targetFormat"/> to anything other than the format
            stored in the file may significantly increase the latency of <see cref="M:K4AdotNet.Record.NativeApi.PlaybackGetNextCapture(K4AdotNet.NativeHandles.PlaybackHandle,K4AdotNet.NativeHandles.CaptureHandle@)"/> and
            <see cref="M:K4AdotNet.Record.NativeApi.PlaybackGetPreviousCapture(K4AdotNet.NativeHandles.PlaybackHandle,K4AdotNet.NativeHandles.CaptureHandle@)"/>.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Record.NativeApi.PlaybackGetNextCapture(K4AdotNet.NativeHandles.PlaybackHandle,K4AdotNet.NativeHandles.CaptureHandle@)">
            <summary>Read the next capture in the recording sequence.</summary>
            <param name="playbackHandle">Handle obtained by <see cref="M:K4AdotNet.Record.NativeApi.PlaybackOpen(System.Byte[],K4AdotNet.NativeHandles.PlaybackHandle@)"/>.</param>
            <param name="captureHandle">If successful this contains a handle to a capture object.</param>
            <returns>
            <see cref="F:K4AdotNet.NativeCallResults.StreamResult.Succeeded"/> if a capture is returned, or <see cref="F:K4AdotNet.NativeCallResults.StreamResult.Eof"/>
            if the end of the recording is reached. All other failures will return <see cref="F:K4AdotNet.NativeCallResults.StreamResult.Failed"/>.
            </returns>
            <remarks>
            This method always returns the next capture in sequence after the most recently returned capture.
            
            The first call to this method after <see cref="M:K4AdotNet.Record.NativeApi.PlaybackSeekTimestamp(K4AdotNet.NativeHandles.PlaybackHandle,K4AdotNet.Microseconds64,K4AdotNet.Record.PlaybackSeekOrigin)"/> will return the capture
            in the recording closest to the seek time with an image timestamp greater than or equal to the seek time.
            
            If a call was made to <see cref="M:K4AdotNet.Record.NativeApi.PlaybackGetPreviousCapture(K4AdotNet.NativeHandles.PlaybackHandle,K4AdotNet.NativeHandles.CaptureHandle@)"/> that returned <see cref="F:K4AdotNet.NativeCallResults.StreamResult.Eof"/>, the playback
            position is at the beginning of the stream and this method will return the first capture in the recording.
            
            Capture objects returned by the playback API will always contain at least one image, but may have images missing if
            frames were dropped in the original recording. When calling <see cref="M:K4AdotNet.Sensor.NativeApi.CaptureGetColorImage(K4AdotNet.NativeHandles.CaptureHandle)"/>,
            <see cref="M:K4AdotNet.Sensor.NativeApi.CaptureGetDepthImage(K4AdotNet.NativeHandles.CaptureHandle)"/>, or <see cref="M:K4AdotNet.Sensor.NativeApi.CaptureGetIRImage(K4AdotNet.NativeHandles.CaptureHandle)"/>,
            the image should be checked for <see langword="null"/>.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Record.NativeApi.PlaybackGetPreviousCapture(K4AdotNet.NativeHandles.PlaybackHandle,K4AdotNet.NativeHandles.CaptureHandle@)">
            <summary>Read the previous capture in the recording sequence.</summary>
            <param name="playbackHandle">Handle obtained by <see cref="M:K4AdotNet.Record.NativeApi.PlaybackOpen(System.Byte[],K4AdotNet.NativeHandles.PlaybackHandle@)"/>.</param>
            <param name="captureHandle">If successful this contains a handle to a capture object.</param>
            <returns>
            <see cref="F:K4AdotNet.NativeCallResults.StreamResult.Succeeded"/> if a capture is returned, or <see cref="F:K4AdotNet.NativeCallResults.StreamResult.Eof"/>
            if the start of the recording is reached. All other failures will return <see cref="F:K4AdotNet.NativeCallResults.StreamResult.Failed"/>.
            </returns>
            <remarks>
            This method always returns the previous capture in sequence before the most recently returned capture.
            
            The first call to this method after <see cref="M:K4AdotNet.Record.NativeApi.PlaybackSeekTimestamp(K4AdotNet.NativeHandles.PlaybackHandle,K4AdotNet.Microseconds64,K4AdotNet.Record.PlaybackSeekOrigin)"/> will return the capture
            in the recording closest to the seek time with all image time stamps less than the seek time.
            
            If a call was made to <see cref="M:K4AdotNet.Record.NativeApi.PlaybackGetNextCapture(K4AdotNet.NativeHandles.PlaybackHandle,K4AdotNet.NativeHandles.CaptureHandle@)"/> that returned <see cref="F:K4AdotNet.NativeCallResults.StreamResult.Eof"/>, the playback
            position is at the end of the stream and this method will return the last capture in the recording.
            
            Capture objects returned by the playback API will always contain at least one image, but may have images missing if
            frames were dropped in the original recording. When calling <see cref="M:K4AdotNet.Sensor.NativeApi.CaptureGetColorImage(K4AdotNet.NativeHandles.CaptureHandle)"/>,
            <see cref="M:K4AdotNet.Sensor.NativeApi.CaptureGetDepthImage(K4AdotNet.NativeHandles.CaptureHandle)"/>, or <see cref="M:K4AdotNet.Sensor.NativeApi.CaptureGetIRImage(K4AdotNet.NativeHandles.CaptureHandle)"/>,
            the image should be checked for <see langword="null"/>.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Record.NativeApi.PlaybackGetNextImuSample(K4AdotNet.NativeHandles.PlaybackHandle,K4AdotNet.Sensor.ImuSample@)">
            <summary>Read the next IMU sample in the recording sequence.</summary>
            <param name="playbackHandle">Handle obtained by <see cref="M:K4AdotNet.Record.NativeApi.PlaybackOpen(System.Byte[],K4AdotNet.NativeHandles.PlaybackHandle@)"/>.</param>
            <param name="imuSample">If successful this contains IMU sample.</param>
            <returns>
            <see cref="F:K4AdotNet.NativeCallResults.StreamResult.Succeeded"/> if a sample is returned, or <see cref="F:K4AdotNet.NativeCallResults.StreamResult.Eof"/>
            if the end of the recording is reached. All other failures will return <see cref="F:K4AdotNet.NativeCallResults.StreamResult.Failed"/>.
            </returns>
            <remarks>
            This method always returns the next IMU sample in sequence after the most recently returned sample.
            
            The first call to this method after <see cref="M:K4AdotNet.Record.NativeApi.PlaybackSeekTimestamp(K4AdotNet.NativeHandles.PlaybackHandle,K4AdotNet.Microseconds64,K4AdotNet.Record.PlaybackSeekOrigin)"/> will return the IMU sample
            in the recording closest to the seek time with timestamp greater than or equal to the seek time.
            
            If a call was made to <see cref="M:K4AdotNet.Record.NativeApi.PlaybackGetPreviousImuSample(K4AdotNet.NativeHandles.PlaybackHandle,K4AdotNet.Sensor.ImuSample@)"/> that returned <see cref="F:K4AdotNet.NativeCallResults.StreamResult.Eof"/>, the playback
            position is at the beginning of the stream and this method will return the first IMU sample in the recording.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Record.NativeApi.PlaybackGetPreviousImuSample(K4AdotNet.NativeHandles.PlaybackHandle,K4AdotNet.Sensor.ImuSample@)">
            <summary>Read the previous IMU sample in the recording sequence.</summary>
            <param name="playbackHandle">Handle obtained by <see cref="M:K4AdotNet.Record.NativeApi.PlaybackOpen(System.Byte[],K4AdotNet.NativeHandles.PlaybackHandle@)"/>.</param>
            <param name="imuSample">If successful this contains IMU sample.</param>
            <returns>
            <see cref="F:K4AdotNet.NativeCallResults.StreamResult.Succeeded"/> if a sample is returned, or <see cref="F:K4AdotNet.NativeCallResults.StreamResult.Eof"/>
            if the start of the recording is reached. All other failures will return <see cref="F:K4AdotNet.NativeCallResults.StreamResult.Failed"/>.
            </returns>
            <remarks>
            This method always returns the previous IMU sample in sequence before the most recently returned sample.
            
            The first call to this method after <see cref="M:K4AdotNet.Record.NativeApi.PlaybackSeekTimestamp(K4AdotNet.NativeHandles.PlaybackHandle,K4AdotNet.Microseconds64,K4AdotNet.Record.PlaybackSeekOrigin)"/> will return the IMU sample
            in the recording closest to the seek time with timestamp less than the seek time.
            
            If a call was made to <see cref="M:K4AdotNet.Record.NativeApi.PlaybackGetPreviousImuSample(K4AdotNet.NativeHandles.PlaybackHandle,K4AdotNet.Sensor.ImuSample@)"/> that returned <see cref="F:K4AdotNet.NativeCallResults.StreamResult.Eof"/>, the playback
            position is at the beginning of the stream and this method will return the first IMU sample in the recording.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Record.NativeApi.PlaybackSeekTimestamp(K4AdotNet.NativeHandles.PlaybackHandle,K4AdotNet.Microseconds64,K4AdotNet.Record.PlaybackSeekOrigin)">
            <summary>Seek to a specific timestamp within a recording.</summary>
            <param name="playbackHandle">Handle obtained by <see cref="M:K4AdotNet.Record.NativeApi.PlaybackOpen(System.Byte[],K4AdotNet.NativeHandles.PlaybackHandle@)"/>.</param>
            <param name="offset">The timestamp offset to seek to relative to <paramref name="origin"/>.</param>
            <param name="origin">Specifies if the seek operation should be done relative to the beginning or end of the recording.</param>
            <returns>
            <see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> if the seek operation was successful, or <see cref="F:K4AdotNet.NativeCallResults.Result.Failed"/>
            if an error occurred. The current seek position is left unchanged if a failure is returned.
            </returns>
            <remarks>
            The first call to <see cref="M:K4AdotNet.Record.NativeApi.PlaybackGetNextCapture(K4AdotNet.NativeHandles.PlaybackHandle,K4AdotNet.NativeHandles.CaptureHandle@)"/> after this method
            will return the first capture containing an image timestamp greater than or equal to the seek time.
            
            The first call to <see cref="M:K4AdotNet.Record.NativeApi.PlaybackGetPreviousCapture(K4AdotNet.NativeHandles.PlaybackHandle,K4AdotNet.NativeHandles.CaptureHandle@)"/> after this method
            will return the firs capture with all image timestamps less than the seek time.
            
            The first call to <see cref="M:K4AdotNet.Record.NativeApi.PlaybackGetNextImuSample(K4AdotNet.NativeHandles.PlaybackHandle,K4AdotNet.Sensor.ImuSample@)"/> after this method
            will return the first IMU sample with a timestamp greater than or equal to the seek time.
            
            The first call to <see cref="M:K4AdotNet.Record.NativeApi.PlaybackGetPreviousImuSample(K4AdotNet.NativeHandles.PlaybackHandle,K4AdotNet.Sensor.ImuSample@)"/> after this method
            will return the first IMU sample with a timestamp less than the seek time.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Record.NativeApi.PlaybackGetLastTimestamp(K4AdotNet.NativeHandles.PlaybackHandle)">
            <summary>Gets the last timestamp in a recording.</summary>
            <param name="playbackHandle">Handle obtained by <see cref="M:K4AdotNet.Record.NativeApi.PlaybackOpen(System.Byte[],K4AdotNet.NativeHandles.PlaybackHandle@)"/>.</param>
            <returns>The timestamp of the last capture image or IMU sample.</returns>
            <remarks>Recordings start at timestamp <see cref="F:K4AdotNet.Microseconds64.Zero"/>, and end at the timestamp returned by this method.</remarks>
        </member>
        <member name="T:K4AdotNet.Record.PlaybackSeekOrigin">
            <summary>Playback seeking positions.</summary>
        </member>
        <member name="F:K4AdotNet.Record.PlaybackSeekOrigin.Begin">
            <summary>Seek relative to the beginning of a recording.</summary>
        </member>
        <member name="F:K4AdotNet.Record.PlaybackSeekOrigin.End">
            <summary>Seek relative to the end of a recording.</summary>
        </member>
        <member name="T:K4AdotNet.Record.RecordConfiguration">
            <summary>Structure containing the device configuration used to record.</summary>
        </member>
        <member name="F:K4AdotNet.Record.RecordConfiguration.ColorFormat">
            <summary>Image format used to record the color camera.</summary>
        </member>
        <member name="F:K4AdotNet.Record.RecordConfiguration.ColorResolution">
            <summary>Image resolution used to record the color camera.</summary>
        </member>
        <member name="F:K4AdotNet.Record.RecordConfiguration.DepthMode">
            <summary>Mode used to record the depth camera.</summary>
        </member>
        <member name="F:K4AdotNet.Record.RecordConfiguration.CameraFps">
            <summary>Frame rate used to record the color and depth camera.</summary>
        </member>
        <member name="F:K4AdotNet.Record.RecordConfiguration.ColorTrackEnabled">
            <summary><see langword="true"/> if the recording contains Color camera frames.</summary>
        </member>
        <member name="F:K4AdotNet.Record.RecordConfiguration.DepthTrackEnabled">
            <summary><see langword="true"/> if the recording contains Depth camera frames.</summary>
        </member>
        <member name="F:K4AdotNet.Record.RecordConfiguration.IRTrackEnabled">
            <summary><see langword="true"/> if the recording contains IR camera frames.</summary>
        </member>
        <member name="F:K4AdotNet.Record.RecordConfiguration.ImuTrackEnabled">
            <summary><see langword="true"/> if the recording contains IMU sample data.</summary>
        </member>
        <member name="F:K4AdotNet.Record.RecordConfiguration.DepthDelayOffColor">
            <summary>
            The delay between color and depth images in the recording.
            A negative delay means depth images are first, and a positive delay means color images are first.
            </summary>
        </member>
        <member name="F:K4AdotNet.Record.RecordConfiguration.WiredSyncMode">
            <summary>External synchronization mode.</summary>
        </member>
        <member name="F:K4AdotNet.Record.RecordConfiguration.SubordinateDelayOffMaster">
            <summary>
            The timestamp offset of the start of the recording. All recorded time stamps are offset by this value such that
            the recording starts at timestamp <see cref="F:K4AdotNet.Microseconds32.Zero"/>. This value can be used to synchronize time stamps between two recording files.
            </summary>
        </member>
        <member name="F:K4AdotNet.Sdk.SENSOR_DLL_NAME">
            <summary>Name of Kinect for Azure Sensor SDK DLL.</summary>
        </member>
        <member name="F:K4AdotNet.Sdk.RECORD_DLL_NAME">
            <summary>Name of record DLL in Kinect for Azure Sensor SDK.</summary>
        </member>
        <member name="F:K4AdotNet.Sdk.BODY_TRACKING_DLL_NAME">
            <summary>Name of Kinect for Azure Body Tracking SDK DLL.</summary>
        </member>
        <member name="M:K4AdotNet.Sdk.ConfigureLogging(System.Diagnostics.TraceLevel,System.Boolean,System.String)">
            <summary>The Sensor SDK can log data to the console, files, or to a custom handler.</summary>
            <param name="level">Level of logging.</param>
            <param name="logToStdout">Log messages to STDOUT?</param>
            <param name="logToFile">
            Log all messages to the path and file specified.
            Must end in '.log' to be considered a valid entry.
            Use <see langword="null"/> or empty string to completely disable logging to a file.
            </param>
        </member>
        <member name="M:K4AdotNet.Sdk.ConfigureBodyTrackingLogging(System.Diagnostics.TraceLevel)">
            <summary>Current version of Body Tracking SDK can log data only to the console.</summary>
            <param name="level">Level of logging.</param>
        </member>
        <member name="T:K4AdotNet.Sensor.Calibration">
            <summary>Information about device calibration in particular depth mode and color resolution.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.Calibration.DepthCameraCalibration">
            <summary>Depth camera calibration.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.Calibration.ColorCameraCalibration">
            <summary>Color camera calibration.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.Calibration.Extrinsics">
            <summary>Extrinsic transformation parameters.</summary>
            <remarks>
            The extrinsic parameters allow 3D coordinate conversions between depth camera, color camera, the IMU's gyroscope
            and accelerometer.To transform from a source to a target 3D coordinate system, use the parameters stored
            under <c>Extrinsics[source * (int)CalibrationSensor.Count + target]</c>.
            </remarks>
            <seealso cref="M:K4AdotNet.Sensor.Calibration.GetExtrinsics(K4AdotNet.Sensor.CalibrationGeometry,K4AdotNet.Sensor.CalibrationGeometry)"/>
        </member>
        <member name="F:K4AdotNet.Sensor.Calibration.DepthMode">
            <summary>Depth camera mode for which calibration was obtained.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.Calibration.ColorResolution">
            <summary>Color camera resolution for which calibration was obtained.</summary>
        </member>
        <member name="T:K4AdotNet.Sensor.CalibrationExtrinsics">
            <summary>Extrinsic calibration defines the physical relationship between two separate sensors inside Kinect for Azure device.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationExtrinsics.Rotation">
            <summary>Rotation matrix.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationExtrinsics.Translation">
            <summary>Translation vector.</summary>
        </member>
        <member name="T:K4AdotNet.Sensor.CalibrationGeometry">
            <summary>Kinect for Azure device consists of different sensors each of them has their own coordinate system and calibration extrinsics.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationGeometry.Unknown">
            <summary>Calibration type is unknown.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationGeometry.Depth">
            <summary>Depth sensor.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationGeometry.Color">
            <summary>Color sensor.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationGeometry.Gyro">
            <summary>Gyroscope sensor.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationGeometry.Accel">
            <summary>Accelerometer sensor.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationGeometry.Count">
            <summary>Number of types excluding unknown type.</summary>
        </member>
        <member name="T:K4AdotNet.Sensor.CalibrationIntrinsicParameters">
            <summary>Intrinsic calibration represents the internal optical properties of the camera.</summary>
            <remarks>Azure Kinect devices are calibrated with Brown Conrady which is compatible with OpenCV.</remarks>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationIntrinsicParameters.Cx">
            <summary>Principal point in image, x. Corresponding index in array: 0.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationIntrinsicParameters.Cy">
            <summary>Principal point in image, y. Corresponding index in array: 1.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationIntrinsicParameters.Fx">
            <summary>Focal length x. Corresponding index in array: 2.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationIntrinsicParameters.Fy">
            <summary>Focal length y. Corresponding index in array: 3.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationIntrinsicParameters.K1">
            <summary>k1 radial distortion coefficient. Corresponding index in array: 4.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationIntrinsicParameters.K2">
            <summary>kw radial distortion coefficient. Corresponding index in array: 5.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationIntrinsicParameters.K3">
            <summary>k3 radial distortion coefficient. Corresponding index in array: 6.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationIntrinsicParameters.K4">
            <summary>k4 radial distortion coefficient. Corresponding index in array: 7.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationIntrinsicParameters.K5">
            <summary>k5 radial distortion coefficient. Corresponding index in array: 8.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationIntrinsicParameters.K6">
            <summary>k6 radial distortion coefficient. Corresponding index in array: 9.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationIntrinsicParameters.Codx">
            <summary>Center of distortion in Z=1 plane, x (only used for Rational6KT). Corresponding index in array: 10.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationIntrinsicParameters.Cody">
            <summary>Center of distortion in Z=1 plane, y (only used for Rational6KT). Corresponding index in array: 11.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationIntrinsicParameters.P2">
            <summary>Tangential distortion coefficient 2. Corresponding index in array: 12.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationIntrinsicParameters.P1">
            <summary>Tangential distortion coefficient 1. Corresponding index in array: 13.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationIntrinsicParameters.MetricRadius">
            <summary>Metric radius. Corresponding index in array: 14.</summary>
        </member>
        <member name="M:K4AdotNet.Sensor.CalibrationIntrinsicParameters.ToArray">
            <summary>Array representation of intrinsic model parameters.</summary>
        </member>
        <member name="T:K4AdotNet.Sensor.CalibrationIntrinsics">
            <summary>Camera sensor intrinsic calibration data.</summary>
            <remarks>
            Intrinsic calibration represents the internal optical properties of the camera.
            
            Azure Kinect devices are calibrated with Brown Conrady which is compatible with OpenCV.
            </remarks>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationIntrinsics.Model">
            <summary>Type of calibration model used.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationIntrinsics.ParameterCount">
            <summary>Number of valid entries in <see cref="F:K4AdotNet.Sensor.CalibrationIntrinsics.Parameters"/>.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationIntrinsics.Parameters">
            <summary>Calibration parameters.</summary>
        </member>
        <member name="T:K4AdotNet.Sensor.CalibrationModel">
            <summary>The model used to interpret the calibration parameters.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationModel.Unknown">
            <summary>Calibration model is unknown.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationModel.Theta">
            <summary>Calibration model is Theta (arctan).</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationModel.Polynomial3K">
            <summary>Calibration model Polynomial 3K.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationModel.Rational6KT">
            <summary>Calibration model Rational 6KT.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CalibrationModel.BrownConrady">
            <summary>Calibration model Brown Conrady (compatible with OpenCV).</summary>
        </member>
        <member name="T:K4AdotNet.Sensor.CameraCalibration">
            <summary>Camera calibration contains intrinsic and extrinsic calibration information for depth/color camera.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CameraCalibration.Extrinsics">
            <summary>Extrinsic calibration data.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CameraCalibration.Intrinsics">
            <summary>Intrinsic calibration data.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CameraCalibration.ResolutionWidth">
            <summary>Resolution width of the camera.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CameraCalibration.ResolutionHeight">
            <summary>Resolution height of the camera.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.CameraCalibration.MetricRadius">
            <summary>Max FOV of the camera.</summary>
        </member>
        <member name="T:K4AdotNet.Sensor.ColorControlCommand">
            <summary>Color sensor control commands.</summary>
            <remarks>
            Control values set on a device are reset only when the device is power cycled. The device will retain the settings
            even if the device is closed or the application is restarted.
            </remarks>
        </member>
        <member name="F:K4AdotNet.Sensor.ColorControlCommand.ExposureTimeAbsolute">
            <summary>Exposure time setting.</summary>
            <remarks>
            May be set to <see cref="F:K4AdotNet.Sensor.ColorControlMode.Auto"/> or <see cref="F:K4AdotNet.Sensor.ColorControlMode.Manual"/>.
            Exposure time is measured in microseconds.
            </remarks>
        </member>
        <member name="F:K4AdotNet.Sensor.ColorControlCommand.AutoExposurePriority">
            <summary>Exposure or Framerate priority setting.</summary>
            <remarks>
            May only be set to <see cref="F:K4AdotNet.Sensor.ColorControlMode.Manual"/>.
            Value of <c>0</c> means framerate priority. Value of <c>1</c> means exposure priority.
            Using exposure priority may impact the framerate of both the color and depth cameras.
            Deprecated starting in 1.1.0. Please discontinue usage, firmware does not support this.
            </remarks>
        </member>
        <member name="F:K4AdotNet.Sensor.ColorControlCommand.Brightness">
            <summary>Brightness setting.</summary>
            <remarks>
            May only be set to <see cref="F:K4AdotNet.Sensor.ColorControlMode.Manual"/>.
            The valid range is 0 to 255. The default value is 128.
            </remarks>
        </member>
        <member name="F:K4AdotNet.Sensor.ColorControlCommand.Contrast">
            <summary>Contrast setting.</summary>
            <remarks>
            May only be set to <see cref="F:K4AdotNet.Sensor.ColorControlMode.Manual"/>.
            </remarks>
        </member>
        <member name="F:K4AdotNet.Sensor.ColorControlCommand.Saturation">
            <summary>Saturation setting.</summary>
            <remarks>
            May only be set to <see cref="F:K4AdotNet.Sensor.ColorControlMode.Manual"/>.
            </remarks>
        </member>
        <member name="F:K4AdotNet.Sensor.ColorControlCommand.Sharpness">
            <summary>Sharpness setting.</summary>
            <remarks>
            May only be set to <see cref="F:K4AdotNet.Sensor.ColorControlMode.Manual"/>.
            </remarks>
        </member>
        <member name="F:K4AdotNet.Sensor.ColorControlCommand.Whitebalance">
            <summary>White balance setting.</summary>
            <remarks>
            May be set to <see cref="F:K4AdotNet.Sensor.ColorControlMode.Auto"/> or <see cref="F:K4AdotNet.Sensor.ColorControlMode.Manual"/>.
            The unit is degrees Kelvin. The setting must be set to a value evenly divisible by 10 degrees.
            </remarks>
        </member>
        <member name="F:K4AdotNet.Sensor.ColorControlCommand.BacklightCompensation">
            <summary>Backlight compensation setting.</summary>
            <remarks>
            May only be set to <see cref="F:K4AdotNet.Sensor.ColorControlMode.Manual"/>.
            Value of <c>0</c> means backlight compensation is disabled. Value of <c>1</c> means backlight compensation is enabled.
            </remarks>
        </member>
        <member name="F:K4AdotNet.Sensor.ColorControlCommand.Gain">
            <summary>Gain setting.</summary>
            <remarks>
            May only be set to <see cref="F:K4AdotNet.Sensor.ColorControlMode.Manual"/>.
            </remarks>
        </member>
        <member name="F:K4AdotNet.Sensor.ColorControlCommand.PowerlineFrequency">
            <summary>Powerline frequency setting.</summary>
            <remarks>
            May only be set to <see cref="F:K4AdotNet.Sensor.ColorControlMode.Manual"/>.
            Value of <c>1</c> sets the powerline compensation to 50 Hz. Value of <c>2</c> sets the powerline compensation to 60 Hz.
            </remarks>
        </member>
        <member name="T:K4AdotNet.Sensor.ColorControlMode">
            <summary>Color sensor control mode.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.ColorControlMode.Auto">
            <summary>set the associated <see cref="T:K4AdotNet.Sensor.ColorControlCommand"/> to auto mode</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.ColorControlMode.Manual">
            <summary>set the associated <see cref="T:K4AdotNet.Sensor.ColorControlCommand"/> to manual mode</summary>
        </member>
        <member name="T:K4AdotNet.Sensor.ColorResolution">
            <summary>Color sensor resolutions.</summary>
            <seealso cref="T:K4AdotNet.Sensor.ColorResolutions"/>
        </member>
        <member name="F:K4AdotNet.Sensor.ColorResolution.Off">
            <summary>Color camera will be turned off with this setting</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.ColorResolution.R720p">
            <summary>1280x720  16:9</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.ColorResolution.R1080p">
            <summary>1920x1080 16:9</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.ColorResolution.R1440p">
            <summary>2560x1440 16:9</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.ColorResolution.R1536p">
            <summary>2048x1536 4:3</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.ColorResolution.R2160p">
            <summary>3840x2160 16:9</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.ColorResolution.R3072p">
            <summary>4096x3072 4:3</summary>
        </member>
        <member name="T:K4AdotNet.Sensor.ColorResolutions">
            <summary>Helper extension methods for <see cref="T:K4AdotNet.Sensor.ColorResolution"/> enumeration.</summary>
        </member>
        <member name="M:K4AdotNet.Sensor.ColorResolutions.WidthPixels(K4AdotNet.Sensor.ColorResolution)">
            <summary>Returns image width in pixels for a given resolution.</summary>
        </member>
        <member name="M:K4AdotNet.Sensor.ColorResolutions.HeightPixels(K4AdotNet.Sensor.ColorResolution)">
            <summary>Returns image height in pixels for a given resolution.</summary>
        </member>
        <member name="T:K4AdotNet.Sensor.DepthMode">
            <summary>Depth sensor capture modes.</summary>
            <remarks>
            See the hardware specification for additional details on the field of view, and supported frame rates
            for each mode.
            
            Binned modes reduce the captured camera resolution by combining adjacent sensor pixels into a bin.
            </remarks>
            <seealso cref="T:K4AdotNet.Sensor.DepthModes"/>
        </member>
        <member name="F:K4AdotNet.Sensor.DepthMode.Off">
            <summary>Depth sensor will be turned off with this setting.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.DepthMode.NarrowView2x2Binned">
            <summary>Depth captured at 320x288. Passive IR is also captured at 320x288.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.DepthMode.NarrowViewUnbinned">
            <summary>Depth captured at 640x576. Passive IR is also captured at 640x576.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.DepthMode.WideView2x2Binned">
            <summary>Depth captured at 512x512. Passive IR is also captured at 512x512.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.DepthMode.WideViewUnbinned">
            <summary>Depth captured at 1024x1024. Passive IR is also captured at 1024x1024.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.DepthMode.PassiveIR">
            <summary>Passive IR only, captured at 1024x1024.</summary>
        </member>
        <member name="T:K4AdotNet.Sensor.DepthModes">
            <summary>Helper extension methods for <see cref="T:K4AdotNet.Sensor.DepthMode"/> enumeration.</summary>
        </member>
        <member name="M:K4AdotNet.Sensor.DepthModes.WidthPixels(K4AdotNet.Sensor.DepthMode)">
            <summary>Returns depth and IR images width in pixels for a given depth mode.</summary>
        </member>
        <member name="M:K4AdotNet.Sensor.DepthModes.HeightPixels(K4AdotNet.Sensor.DepthMode)">
            <summary>Returns depth and IR images height in pixels for a given depth mode.</summary>
        </member>
        <member name="M:K4AdotNet.Sensor.DepthModes.IsWideView(K4AdotNet.Sensor.DepthMode)">
            <summary>Is depth mode has wide field of view?</summary>
        </member>
        <member name="M:K4AdotNet.Sensor.DepthModes.IsBinned(K4AdotNet.Sensor.DepthMode)">
            <summary>Does depth mode use binning for smoothing/filtering?</summary>
        </member>
        <member name="T:K4AdotNet.Sensor.DeviceConfiguration">
            <summary>Configuration parameters for an Azure Kinect device.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.DeviceConfiguration.ColorFormat">
            <summary>Image format to capture with the color camera.</summary>
            <remarks>
            The color camera does not natively produce BGRA32 images.
            Setting <see cref="F:K4AdotNet.Sensor.ImageFormat.ColorBgra32"/> value will result in higher CPU utilization.
            </remarks>
        </member>
        <member name="F:K4AdotNet.Sensor.DeviceConfiguration.ColorResolution">
            <summary>Image resolution to capture with the color camera.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.DeviceConfiguration.DepthMode">
            <summary>Capture mode for the depth camera.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.DeviceConfiguration.CameraFps">
            <summary>Desired frame rate for the color and depth camera.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.DeviceConfiguration.SynchronizedImagesOnly">
            <summary>Only produce capture objects if they contain synchronized color and depth images.</summary>
            <remarks>
            This setting controls the behavior in which images are dropped when images are produced faster than they can be
            read, or if there are errors in reading images from the device.
            
            If set to <see langword="true"/>, capture objects will only be produced with both color and depth images.
            If set to <see langword="false"/>, capture objects may be produced only a single image when the corresponding image is dropped.
            
            Setting this to <see langword="false"/> ensures that the caller receives all of the images received from the camera, regardless of
            whether the corresponding images expected in the capture are available.
            
            If either the color or depth camera are disabled, this setting has no effect.
            </remarks>
        </member>
        <member name="F:K4AdotNet.Sensor.DeviceConfiguration.DepthDelayOffColor">
            <summary>Desired delay between the capture of the color image and the capture of the depth image.</summary>
            <remarks>
            A negative value indicates that the depth image should be captured before the color image.
            Any value between negative and positive one capture period is valid.
            </remarks>
        </member>
        <member name="F:K4AdotNet.Sensor.DeviceConfiguration.WiredSyncMode">
            <summary>The external synchronization mode.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.DeviceConfiguration.SubordinateDelayOffMaster">
            <summary>The external synchronization timing.</summary>
            <remarks>
            If this camera is a subordinate, this sets the capture delay between the color camera capture and the external
            input pulse. A setting of zero indicates that the master and subordinate color images should be aligned.
            
            This setting does not effect the 'Sync out' connection.
            
            This value must be positive and range from zero to one capture period.
            
            If this is not a subordinate, then this value is ignored.
            </remarks>
        </member>
        <member name="F:K4AdotNet.Sensor.DeviceConfiguration.DisableStreamingIndicator">
            <summary>Streaming indicator automatically turns on when the color or depth camera's are in use.</summary>
            <remarks>This setting disables that behavior and keeps the LED in an off state.</remarks>
        </member>
        <member name="F:K4AdotNet.Sensor.DeviceConfiguration.DisableAll">
            <summary>Initial configuration setting for disabling all sensors.</summary>
            <remarks>Use this setting to initialize a <see cref="T:K4AdotNet.Sensor.DeviceConfiguration"/> to a disabled state.</remarks>
        </member>
        <member name="T:K4AdotNet.Sensor.FirmwareBuild">
            <summary>Firmware build type.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.FirmwareBuild.Release">
            <summary>Production firmware.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.FirmwareBuild.Debug">
            <summary>Pre-production firmware.</summary>
        </member>
        <member name="T:K4AdotNet.Sensor.FirmwareSignature">
            <summary>Firmware signature type.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.FirmwareSignature.MicrosoftSignedFirmware">
            <summary>Microsoft signed firmware.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.FirmwareSignature.TestSignedFirmware">
            <summary>Test signed firmware.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.FirmwareSignature.UnsignedFirmware">
            <summary>Unsigned firmware.</summary>
        </member>
        <member name="T:K4AdotNet.Sensor.FirmwareVersion">
            <summary>
            Version information about sensor firmware.
            </summary>
        </member>
        <member name="F:K4AdotNet.Sensor.FirmwareVersion.Major">
            <summary>Major version; represents a breaking change.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.FirmwareVersion.Minor">
            <summary>Minor version; represents additional features, no regression from lower versions with same major version.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.FirmwareVersion.Revision">
            <summary>Reserved.</summary>
        </member>
        <member name="M:K4AdotNet.Sensor.FirmwareVersion.#ctor(System.Int32,System.Int32,System.Int32)">
            <summary>Creates version with specified components.</summary>
            <param name="major">Value for field <see cref="F:K4AdotNet.Sensor.FirmwareVersion.Major"/>.</param>
            <param name="minor">Value for field <see cref="F:K4AdotNet.Sensor.FirmwareVersion.Minor"/>.</param>
            <param name="revision">Value for field <see cref="F:K4AdotNet.Sensor.FirmwareVersion.Revision"/>.</param>
        </member>
        <member name="M:K4AdotNet.Sensor.FirmwareVersion.Equals(K4AdotNet.Sensor.FirmwareVersion)">
            <summary>Per-component comparison of versions.</summary>
            <param name="other">Version to be compared with this one.</param>
            <returns><c>true</c> - versions are the same, <c>false</c> - versions are differ from each other.</returns>
        </member>
        <member name="T:K4AdotNet.Sensor.FrameRate">
            <summary>Color and depth sensor frame rate.</summary>
            <remarks>
            This enumeration is used to select the desired frame rate to operate the cameras. The actual
            frame rate may vary slightly due to dropped data, synchronization variation between devices,
            clock accuracy, or if the camera exposure priority mode causes reduced frame rate.
            </remarks>
            <seealso cref="T:K4AdotNet.Sensor.FrameRates"/>
        </member>
        <member name="F:K4AdotNet.Sensor.FrameRate.Five">
            <summary>Five (5) frames per second.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.FrameRate.Fifteen">
            <summary>Fifteen (15) frames per second.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.FrameRate.Thirty">
            <summary>Thirty (30) frames per second.</summary>
        </member>
        <member name="T:K4AdotNet.Sensor.FrameRates">
            <summary>Helper extension and static methods for <see cref="T:K4AdotNet.Sensor.FrameRate"/> enumeration.</summary>
        </member>
        <member name="M:K4AdotNet.Sensor.FrameRates.ToNumberHz(K4AdotNet.Sensor.FrameRate)">
            <summary>Convert enumeration value to appropriate number of frames per second (Hz).</summary>
        </member>
        <member name="M:K4AdotNet.Sensor.FrameRates.FromNumberHz(System.Int32)">
            <summary>Constructs enumeration value from appropriate number of frames per second (Hz).</summary>
        </member>
        <member name="T:K4AdotNet.Sensor.HardwareVersion">
            <summary>Structure to define hardware version.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.HardwareVersion.ColorCameraFirmwareVersion">
            <summary>Color camera firmware version.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.HardwareVersion.DepthCamereFirmwareVersion">
            <summary>Depth camera firmware version.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.HardwareVersion.AudioDeviceFirmwareVersion">
            <summary>Audio device firmware version.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.HardwareVersion.DepthSensorFirmwareVersion">
            <summary>Depth sensor firmware version.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.HardwareVersion.FirmwareBuild">
            <summary>Build type reported by the firmware.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.HardwareVersion.FirmwareSignature">
            <summary>Signature type of the firmware.</summary>
        </member>
        <member name="T:K4AdotNet.Sensor.ImageFormat">
            <summary>Image format type.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.ImageFormat.ColorMjpg">
            <summary>
            The buffer for each image is encoded as a JPEG and can be decoded by a JPEG decoder.
            </summary>
            <remarks>
            Because the image is compressed, the stride parameter is not applicable.
            Each MJPG encoded image in a stream may be of differing size depending on the compression efficiency.
            </remarks>
        </member>
        <member name="F:K4AdotNet.Sensor.ImageFormat.ColorNV12">
            <summary>
            NV12 images separate the luminance and chroma data such that all the luminance is at the
            beginning of the buffer, and the chroma lines follow immediately after.
            </summary>
            <remarks>
            Stride indicates the length of each line in bytes and should be used to determine the start location of each line
            of the image in memory. Chroma has half as many lines of height and half the width in pixels of the luminance.
            Each chroma line has the same width in bytes as a luminance line.
            </remarks>
        </member>
        <member name="F:K4AdotNet.Sensor.ImageFormat.ColorYUY2">
            <summary>
            YUY2 stores chroma and luminance data in interleaved pixels.
            </summary>
            <remarks>
            Stride indicates the length of each line in bytes and should be used to determine the start location of each
            line of the image in memory.
            </remarks>
        </member>
        <member name="F:K4AdotNet.Sensor.ImageFormat.ColorBgra32">
             <summary>
             Each pixel of BGRA32 data is four bytes. The first three bytes represent Blue, Green,
             and Red data. The fourth byte is the alpha channel and is unused in the Azure Kinect APIs.
             </summary>
             <remarks>
             Stride indicates the length of each line in bytes and should be used to determine the start location of each
             line of the image in memory.
            
             The Azure Kinect device does not natively capture in this format. Requesting images of this format
             requires additional computation in the API.
             </remarks>
        </member>
        <member name="F:K4AdotNet.Sensor.ImageFormat.Depth16">
            <summary>
            Each pixel of DEPTH16 data is two bytes of little endian unsigned depth data. The unit of the data is in
            millimeters from the origin of the camera.
            </summary>
            <remarks>
            Stride indicates the length of each line in bytes and should be used to determine the start location of each
            line of the image in memory.
            </remarks>
        </member>
        <member name="F:K4AdotNet.Sensor.ImageFormat.IR16">
            <summary>
            This format represents infrared light and is captured by the depth camera.
            Each pixel of IR16 data is two bytes of little endian unsigned depth data. The value of the data represents
            brightness.
            </summary>
            <remarks>
            Stride indicates the length of each line in bytes and should be used to determine the start location of each
            line of the image in memory.
            </remarks>
        </member>
        <member name="F:K4AdotNet.Sensor.ImageFormat.Custom">
            <summary>
            Custom image format.
            Used in conjunction with user created images or images packing non-standard data.
            </summary>
            <remarks>
            See the originator of the custom formatted image for information on how to interpret the data.
            </remarks>
        </member>
        <member name="T:K4AdotNet.Sensor.ImuSample">
            <summary>IMU sample.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.ImuSample.Temperature">
            <summary>Temperature reading of this sample (Celsius).</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.ImuSample.AccelerometerSample">
            <summary>Accelerometer sample in meters per second squared.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.ImuSample.AccelerometerTimestamp">
            <summary>Time stamp of the accelerometer.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.ImuSample.GyroSample">
            <summary>Gyro sample in radians per second.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.ImuSample.GyroTimestamp">
            <summary>Time stamp of the gyroscope in microseconds.</summary>
        </member>
        <member name="T:K4AdotNet.Sensor.NativeApi">
            <summary>DLL imports for most of native functions from <c>k4a.h</c> header file.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.NativeApi.DEFAULT_DEVICE_INDEX">
            <summary>Default device index.</summary>
            <remarks>Passed as an argument to <see cref="M:K4AdotNet.Sensor.NativeApi.DeviceOpen(System.UInt32,K4AdotNet.NativeHandles.DeviceHandle@)"/> to open the default sensor.</remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.DeviceGetInstalledCount">
            <summary>Gets the number of connected devices.</summary>
            <returns>Number of sensors connected to the PC.</returns>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.DeviceOpen(System.UInt32,K4AdotNet.NativeHandles.DeviceHandle@)">
            <summary>Open an Azure Kinect device.</summary>
            <param name="index">The index of the device to open, starting with 0. Use <see cref="F:K4AdotNet.Sensor.NativeApi.DEFAULT_DEVICE_INDEX"/> constant as value for this parameter to open default device.</param>
            <param name="deviceHandle">Output parameter which on success will return a handle to the device.</param>
            <returns><see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> if the device was opened successfully.</returns>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.DeviceGetCapture(K4AdotNet.NativeHandles.DeviceHandle,K4AdotNet.NativeHandles.CaptureHandle@,K4AdotNet.Timeout)">
            <summary>Reads a sensor capture.</summary>
            <param name="deviceHandle">Handle obtained by <see cref="M:K4AdotNet.Sensor.NativeApi.DeviceOpen(System.UInt32,K4AdotNet.NativeHandles.DeviceHandle@)"/>.</param>
            <param name="captureHandle">If successful this contains a handle to a capture object.</param>
            <param name="timeout">
            Specifies the time the function should block waiting for the capture.
            If set to <see cref="F:K4AdotNet.Timeout.NoWait"/>, the function will return without blocking.
            Passing <see cref="F:K4AdotNet.Timeout.Infinite"/> will block indefinitely until data is available, the
            device is disconnected, or another error occurs.
            </param>
            <returns>
            <see cref="F:K4AdotNet.NativeCallResults.WaitResult.Succeeded"/> if a capture is returned.
            If a capture is not available before the timeout elapses, the function will return <see cref="F:K4AdotNet.NativeCallResults.WaitResult.Timeout"/>.
            All other failures will return <see cref="F:K4AdotNet.NativeCallResults.WaitResult.Failed"/>.
            </returns>
            <remarks>
            This function needs to be called while the device is in a running state;
            after <see cref="M:K4AdotNet.Sensor.NativeApi.DeviceStartCameras(K4AdotNet.NativeHandles.DeviceHandle,K4AdotNet.Sensor.DeviceConfiguration@)"/> is called and before <see cref="M:K4AdotNet.Sensor.NativeApi.DeviceStopCameras(K4AdotNet.NativeHandles.DeviceHandle)"/> is called.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.DeviceGetImuSample(K4AdotNet.NativeHandles.DeviceHandle,K4AdotNet.Sensor.ImuSample@,K4AdotNet.Timeout)">
            <summary>Reads an IMU sample.</summary>
            <param name="deviceHandle">Handle obtained by <see cref="M:K4AdotNet.Sensor.NativeApi.DeviceOpen(System.UInt32,K4AdotNet.NativeHandles.DeviceHandle@)"/>.</param>
            <param name="imuSample">Information about IMU sample.</param>
            <param name="timeout">
            Specifies the time the function should block waiting for the sample.
            If set to <see cref="F:K4AdotNet.Timeout.NoWait"/>, the function will return without blocking.
            Passing <see cref="F:K4AdotNet.Timeout.Infinite"/> will block indefinitely until data is available, the
            device is disconnected, or another error occurs.
            </param>
            <returns>
            <see cref="F:K4AdotNet.NativeCallResults.WaitResult.Succeeded"/> if a sample is returned.
            If a sample is not available before the timeout elapses, the function will return <see cref="F:K4AdotNet.NativeCallResults.WaitResult.Timeout"/>.
            All other failures will return <see cref="F:K4AdotNet.NativeCallResults.WaitResult.Failed"/>.
            </returns>
            <remarks>
            This function needs to be called while the device is in a running state;
            after <see cref="M:K4AdotNet.Sensor.NativeApi.DeviceStartCameras(K4AdotNet.NativeHandles.DeviceHandle,K4AdotNet.Sensor.DeviceConfiguration@)"/> is called and before <see cref="M:K4AdotNet.Sensor.NativeApi.DeviceStopCameras(K4AdotNet.NativeHandles.DeviceHandle)"/> is called.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.CaptureCreate(K4AdotNet.NativeHandles.CaptureHandle@)">
            <summary>Create an empty capture object.</summary>
            <param name="captureHandle">Output parameter which on success will return a handle to the capture.</param>
            <returns><see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> if the device was opened successfully.</returns>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.CaptureGetColorImage(K4AdotNet.NativeHandles.CaptureHandle)">
            <summary>Get the color image associated with the given capture.</summary>
            <param name="captureHandle">Capture handle containing the image.</param>
            <returns>Image handle.</returns>
            <remarks>Call this function to access the color image part of this capture.</remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.CaptureGetDepthImage(K4AdotNet.NativeHandles.CaptureHandle)">
            <summary>Get the depth image associated with the given capture.</summary>
            <param name="captureHandle">Capture handle containing the image.</param>
            <returns>Image handle.</returns>
            <remarks>Call this function to access the depth image part of this capture.</remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.CaptureGetIRImage(K4AdotNet.NativeHandles.CaptureHandle)">
            <summary>Get the IR image associated with the given capture.</summary>
            <param name="captureHandle">Capture handle containing the image.</param>
            <returns>Image handle.</returns>
            <remarks>Call this function to access the IR image part of this capture.</remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.CaptureSetColorImage(K4AdotNet.NativeHandles.CaptureHandle,K4AdotNet.NativeHandles.ImageHandle)">
            <summary>Set or add a color image to the associated capture.</summary>
            <param name="captureHandle">Capture handle to hold the image.</param>
            <param name="imageHandle">Image handle containing the image or <see cref="F:K4AdotNet.NativeHandles.ImageHandle.Zero"/> to remove color image from a given capture if any.</param>
            <remarks>If there is already a color image contained in the capture, the existing image will be dereferenced and replaced with the new image.</remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.CaptureSetDepthImage(K4AdotNet.NativeHandles.CaptureHandle,K4AdotNet.NativeHandles.ImageHandle)">
            <summary>Set or add a depth image to the associated capture.</summary>
            <param name="captureHandle">Capture handle to hold the image.</param>
            <param name="imageHandle">Image handle containing the image or <see cref="F:K4AdotNet.NativeHandles.ImageHandle.Zero"/> to remove depth image from a given capture if any.</param>
            <remarks>If there is already a depth image contained in the capture, the existing image will be dereferenced and replaced with the new image.</remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.CaptureSetIRImage(K4AdotNet.NativeHandles.CaptureHandle,K4AdotNet.NativeHandles.ImageHandle)">
            <summary>Set or add a IR image to the associated capture.</summary>
            <param name="captureHandle">Capture handle to hold the image.</param>
            <param name="imageHandle">Image handle containing the image or <see cref="F:K4AdotNet.NativeHandles.ImageHandle.Zero"/> to remove IR image from a given capture if any.</param>
            <remarks>If there is already a IR image contained in the capture, the existing image will be dereferenced and replaced with the new image.</remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.CaptureSetTemperatureC(K4AdotNet.NativeHandles.CaptureHandle,System.Single)">
            <summary>Set the temperature associated with the capture.</summary>
            <param name="captureHandle">Capture handle to set the temperature on.</param>
            <param name="temperatureC">Temperature in Celsius to store.</param>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.CaptureGetTemperatureC(K4AdotNet.NativeHandles.CaptureHandle)">
            <summary>Get the temperature associated with the capture.</summary>
            <param name="captureHandle">Capture handle to retrieve the temperature from.</param>
            <returns>
            This function returns the temperature of the device at the time of the capture in Celsius.
            If the temperature is unavailable, the function will return <see cref="F:System.Single.NaN"/>.
            </returns>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.ImageCreate(K4AdotNet.Sensor.ImageFormat,System.Int32,System.Int32,System.Int32,K4AdotNet.NativeHandles.ImageHandle@)">
            <summary>
            Create an image.
            </summary>
            <param name="format">The format of the image that will be stored in this image container.</param>
            <param name="widthPixels">Width in pixels.</param>
            <param name="heightPixels">Height in pixels.</param>
            <param name="strideBytes">The number of bytes per horizontal line of the image.</param>
            <param name="imageHandle">Handle of created image in case of success.</param>
            <returns><see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> on success.</returns>
            <remarks>This function is used to create images of formats that have consistent stride.
            The function is not suitable for compressed formats that may not be represented by the same number of bytes per line.
            The function will allocate an image buffer of size <paramref name="heightPixels"/> * <paramref name="strideBytes"/> bytes.
            To create an image object without the API allocating memory, or to represent an image that has a non-deterministic
            stride, use <see cref="M:K4AdotNet.Sensor.NativeApi.ImageCreateFromBuffer(K4AdotNet.Sensor.ImageFormat,System.Int32,System.Int32,System.Int32,System.IntPtr,System.UIntPtr,K4AdotNet.Sensor.NativeApi.MemoryDestroyCallback,System.IntPtr,K4AdotNet.NativeHandles.ImageHandle@)"/>.
            </remarks>
        </member>
        <member name="T:K4AdotNet.Sensor.NativeApi.MemoryDestroyCallback">
            <summary>Callback function for a memory object being destroyed.</summary>
            <param name="buffer">The buffer pointer that was supplied by the caller.</param>
            <param name="context">The context for the memory object that needs to be destroyed that was supplied by the caller.</param>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.ImageCreateFromBuffer(K4AdotNet.Sensor.ImageFormat,System.Int32,System.Int32,System.Int32,System.IntPtr,System.UIntPtr,K4AdotNet.Sensor.NativeApi.MemoryDestroyCallback,System.IntPtr,K4AdotNet.NativeHandles.ImageHandle@)">
            <summary>Create an image from a pre-allocated buffer.</summary>
            <param name="format">The format of the image that will be stored in this image container.</param>
            <param name="widthPixels">Width in pixels.</param>
            <param name="heightPixels">Height in pixels.</param>
            <param name="strideBytes">The number of bytes per horizontal line of the image.</param>
            <param name="buffer">Pointer to a pre-allocated image buffer.</param>
            <param name="bufferSize">Size in bytes of the pre-allocated image buffer.</param>
            <param name="bufferReleaseCallback">
            Callback to the buffer free function, called when all references to the buffer have been released.
            This parameter is optional (can be <see langword="null"/>).</param>
            <param name="bufferReleaseCallbackContext">
            Context for the buffer free function. This value will be called as 2nd parameter to <paramref name="bufferReleaseCallback"/>
            when the callback is invoked.
            </param>
            <param name="imageHandle">Handle of created image in case of success.</param>
            <returns><see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> on success.</returns>
            <remarks>
            This function creates an <see cref="T:K4AdotNet.NativeHandles.ImageHandle"/> from a pre-allocated buffer. When all references to this object reach zero
            the provided <paramref name="bufferReleaseCallback"/> callback function is called so that the memory can be released.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.ImageGetBuffer(K4AdotNet.NativeHandles.ImageHandle)">
            <summary>Get the image buffer.</summary>
            <param name="imageHandle">Handle of the image for which the get operation is performed on.</param>
            <returns>
            The function will return <see cref="F:System.IntPtr.Zero"/> if there is an error, and will normally return a pointer to the image buffer.
            </returns>
            <remarks>Use this buffer to access the raw image data.</remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.ImageGetSize(K4AdotNet.NativeHandles.ImageHandle)">
            <summary>Get the image buffer size.</summary>
            <param name="imageHandle">Handle of the image for which the get operation is performed on.</param>
            <returns>The function will return <see cref="F:System.UIntPtr.Zero"/> if there is an error, and will normally return the image size.</returns>
            <remarks>Use this function to know what the size of the image buffer is returned by <see cref="M:K4AdotNet.Sensor.NativeApi.ImageGetBuffer(K4AdotNet.NativeHandles.ImageHandle)"/>.</remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.ImageGetFormat(K4AdotNet.NativeHandles.ImageHandle)">
            <summary>Get the format of the image.</summary>
            <param name="imageHandle">Handle of the image for which the get operation is performed on.</param>
            <returns>
            This function is not expected to fail, all images are created with a known format.
            If the <paramref name="imageHandle"/> is invalid, the function will return <see cref="F:K4AdotNet.Sensor.ImageFormat.Custom"/>.
            </returns>
            <remarks>Use this function to determine the format of the image buffer.</remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.ImageGetWidthPixels(K4AdotNet.NativeHandles.ImageHandle)">
            <summary>Get the image width in pixels.</summary>
            <param name="imageHandle">Handle of the image for which the get operation is performed on.</param>
            <returns>
            This function is not expected to fail, all images are created with a known width.
            If the <paramref name="imageHandle"/> is invalid, the function will return <c>0</c>.
            </returns>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.ImageGetHeightPixels(K4AdotNet.NativeHandles.ImageHandle)">
            <summary>Get the image height in pixels.</summary>
            <param name="imageHandle">Handle of the image for which the get operation is performed on.</param>
            <returns>
            This function is not expected to fail, all images are created with a known height.
            If the <paramref name="imageHandle"/> is invalid, the function will return <c>0</c>.
            </returns>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.ImageGetStrideBytes(K4AdotNet.NativeHandles.ImageHandle)">
            <summary>Get the image stride in bytes.</summary>
            <param name="imageHandle">Handle of the image for which the get operation is performed on.</param>
            <returns>
            This function is not expected to fail, all images are created with a known stride.
            If the <paramref name="imageHandle"/> is invalid or the image's format does not have a stride, the function will return <c>0</c>.
            </returns>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.ImageGetTimestamp(K4AdotNet.NativeHandles.ImageHandle)">
            <summary>Get the image timestamp.</summary>
            <param name="imageHandle">Handle of the image for which the get operation is performed on.</param>
            <returns>
            If the <paramref name="imageHandle"/> is invalid or if no timestamp was set for the image,
            this function will return <see cref="F:K4AdotNet.Microseconds64.Zero"/>.
            It is also possible for <see cref="F:K4AdotNet.Microseconds64.Zero"/> to be a valid timestamp originating from the beginning
            of a recording or the start of streaming.
            </returns>
            <remarks>
            Returns the timestamp of the image. Time stamps are recorded by the device and represent the mid-point of exposure.
            They may be used for relative comparison, but their absolute value has no defined meaning.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.ImageGetExposureUsec(K4AdotNet.NativeHandles.ImageHandle)">
            <summary>Get the image exposure in microseconds.</summary>
            <param name="imageHandle">Handle of the image for which the get operation is performed on.</param>
            <returns>
            If the <paramref name="imageHandle"/> is invalid or if no exposure was set for the image,
            this function will return <see cref="F:K4AdotNet.Microseconds64.Zero"/>. Otherwise,
            it will return the image exposure time in microseconds.
            </returns>
            <remarks>Returns an exposure time in microseconds. This is only supported on color image formats.</remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.ImageGetWhiteBalance(K4AdotNet.NativeHandles.ImageHandle)">
            <summary>Get the image white balance.</summary>
            <param name="imageHandle">Handle of the image for which the get operation is performed on.</param>
            <returns>
            Returns the image white balance in Kelvin. If <paramref name="imageHandle"/> is invalid, or the white balance was not set or
            not applicable to the image, the function will return <c>0</c>.
            </returns>
            <remarks>Returns the image's white balance. This function is only valid for color captures, and not for depth or IR captures.</remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.ImageGetIsoSpeed(K4AdotNet.NativeHandles.ImageHandle)">
            <summary>Get the image ISO speed.</summary>
            <param name="imageHandle">Handle of the image for which the get operation is performed on.</param>
            <returns>
            Returns the ISO speed of the image. <c>0</c> indicates the ISO speed was not available or an error occurred.
            </returns>
            <remarks>This function is only valid for color captures, and not for depth  or IR captures.</remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.ImageSetTimestamp(K4AdotNet.NativeHandles.ImageHandle,K4AdotNet.Microseconds64)">
            <summary>Set the timestamp, in microseconds, of the image.</summary>
            <param name="imageHandle">Handle of the image to set the timestamp on.</param>
            <param name="timestamp">Time stamp of the image.</param>
            <remarks>
            Use this function in conjunction with <see cref="M:K4AdotNet.Sensor.NativeApi.ImageCreate(K4AdotNet.Sensor.ImageFormat,System.Int32,System.Int32,System.Int32,K4AdotNet.NativeHandles.ImageHandle@)"/>
            or <see cref="M:K4AdotNet.Sensor.NativeApi.ImageCreateFromBuffer(K4AdotNet.Sensor.ImageFormat,System.Int32,System.Int32,System.Int32,System.IntPtr,System.UIntPtr,K4AdotNet.Sensor.NativeApi.MemoryDestroyCallback,System.IntPtr,K4AdotNet.NativeHandles.ImageHandle@)"/> to construct an image.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.ImageSetExposureTimeUsec(K4AdotNet.NativeHandles.ImageHandle,K4AdotNet.Microseconds64)">
            <summary>Set the exposure time, in microseconds, of the image.</summary>
            <param name="imageHandle">Handle of the image to set the exposure time on.</param>
            <param name="exposure">Exposure time of the image in microseconds.</param>
            <remarks>
            Use this function in conjunction with <see cref="M:K4AdotNet.Sensor.NativeApi.ImageCreate(K4AdotNet.Sensor.ImageFormat,System.Int32,System.Int32,System.Int32,K4AdotNet.NativeHandles.ImageHandle@)"/>
            or <see cref="M:K4AdotNet.Sensor.NativeApi.ImageCreateFromBuffer(K4AdotNet.Sensor.ImageFormat,System.Int32,System.Int32,System.Int32,System.IntPtr,System.UIntPtr,K4AdotNet.Sensor.NativeApi.MemoryDestroyCallback,System.IntPtr,K4AdotNet.NativeHandles.ImageHandle@)"/> to construct an image.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.ImageSetWhiteBalance(K4AdotNet.NativeHandles.ImageHandle,System.UInt32)">
            <summary>Set the white balance of the image.</summary>
            <param name="imageHandle">Handle of the image to set the white balance on.</param>
            <param name="whiteBalance">White balance of the image in degrees Kelvin.</param>
            <remarks>
            Use this function in conjunction with <see cref="M:K4AdotNet.Sensor.NativeApi.ImageCreate(K4AdotNet.Sensor.ImageFormat,System.Int32,System.Int32,System.Int32,K4AdotNet.NativeHandles.ImageHandle@)"/>
            or <see cref="M:K4AdotNet.Sensor.NativeApi.ImageCreateFromBuffer(K4AdotNet.Sensor.ImageFormat,System.Int32,System.Int32,System.Int32,System.IntPtr,System.UIntPtr,K4AdotNet.Sensor.NativeApi.MemoryDestroyCallback,System.IntPtr,K4AdotNet.NativeHandles.ImageHandle@)"/> to construct an image.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.ImageSetIsoSpeed(K4AdotNet.NativeHandles.ImageHandle,System.UInt32)">
            <summary>Set the ISO speed of the image.</summary>
            <param name="imageHandle">Handle of the image to set the ISO speed on.</param>
            <param name="isoSpeed">ISO speed of the image.</param>
            <remarks>
            Use this function in conjunction with <see cref="M:K4AdotNet.Sensor.NativeApi.ImageCreate(K4AdotNet.Sensor.ImageFormat,System.Int32,System.Int32,System.Int32,K4AdotNet.NativeHandles.ImageHandle@)"/>
            or <see cref="M:K4AdotNet.Sensor.NativeApi.ImageCreateFromBuffer(K4AdotNet.Sensor.ImageFormat,System.Int32,System.Int32,System.Int32,System.IntPtr,System.UIntPtr,K4AdotNet.Sensor.NativeApi.MemoryDestroyCallback,System.IntPtr,K4AdotNet.NativeHandles.ImageHandle@)"/> to construct an image.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.DeviceStartCameras(K4AdotNet.NativeHandles.DeviceHandle,K4AdotNet.Sensor.DeviceConfiguration@)">
            <summary>Starts color and depth camera capture.</summary>
            <param name="deviceHandle">Handle obtained by <see cref="M:K4AdotNet.Sensor.NativeApi.DeviceOpen(System.UInt32,K4AdotNet.NativeHandles.DeviceHandle@)"/>.</param>
            <param name="config">The configuration we want to run the device in. This can be initialized with <see cref="F:K4AdotNet.Sensor.DeviceConfiguration.DisableAll"/>.</param>
            <returns><see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> is returned on success.</returns>
            <remarks>
            Individual sensors configured to run will now start to stream captured data.
            
            It is not valid to call this method a second time on the same device until <see cref="M:K4AdotNet.Sensor.NativeApi.DeviceStopCameras(K4AdotNet.NativeHandles.DeviceHandle)"/> has been called.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.DeviceStopCameras(K4AdotNet.NativeHandles.DeviceHandle)">
            <summary>Stops the color and depth camera capture.</summary>
            <param name="deviceHandle">Handle obtained by <see cref="M:K4AdotNet.Sensor.NativeApi.DeviceOpen(System.UInt32,K4AdotNet.NativeHandles.DeviceHandle@)"/>.</param>
            <remarks>
            The streaming of individual sensors stops as a result of this call. Once called, <see cref="M:K4AdotNet.Sensor.NativeApi.DeviceStartCameras(K4AdotNet.NativeHandles.DeviceHandle,K4AdotNet.Sensor.DeviceConfiguration@)"/>
            may be called again to resume sensor streaming.
            
            This function may be called while another thread is blocking in <see cref="M:K4AdotNet.Sensor.NativeApi.DeviceGetCapture(K4AdotNet.NativeHandles.DeviceHandle,K4AdotNet.NativeHandles.CaptureHandle@,K4AdotNet.Timeout)"/>.
            Calling this function while another thread is in that function will result in that function returning a failure.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.DeviceStartImu(K4AdotNet.NativeHandles.DeviceHandle)">
            <summary>Starts the IMU sample stream.</summary>
            <param name="deviceHandle">Handle obtained by <see cref="M:K4AdotNet.Sensor.NativeApi.DeviceOpen(System.UInt32,K4AdotNet.NativeHandles.DeviceHandle@)"/>.</param>
            <returns><see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> is returned on success.</returns>
            <remarks>
            Call this API to start streaming IMU data. It is not valid to call this function a second time on the same
            device until <see cref="M:K4AdotNet.Sensor.NativeApi.DeviceStopImu(K4AdotNet.NativeHandles.DeviceHandle)"/> has been called.
            
            This function is dependent on the state of the cameras. The color or depth camera must be started before the IMU.
            <see cref="F:K4AdotNet.NativeCallResults.Result.Failed"/> will be returned if one of the cameras is not running.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.DeviceStopImu(K4AdotNet.NativeHandles.DeviceHandle)">
            <summary>Stops the IMU capture.</summary>
            <param name="deviceHandle">Handle obtained by <see cref="M:K4AdotNet.Sensor.NativeApi.DeviceOpen(System.UInt32,K4AdotNet.NativeHandles.DeviceHandle@)"/>.</param>
            <remarks>
            The streaming of the IMU stops as a result of this call. Once called, <see cref="M:K4AdotNet.Sensor.NativeApi.DeviceStartImu(K4AdotNet.NativeHandles.DeviceHandle)"/> may
            be called again to resume sensor streaming, so long as the cameras are running.
            
            This function may be called while another thread is blocking in <see cref="M:K4AdotNet.Sensor.NativeApi.DeviceGetImuSample(K4AdotNet.NativeHandles.DeviceHandle,K4AdotNet.Sensor.ImuSample@,K4AdotNet.Timeout)"/>.
            Calling this function while another thread is in that function will result in that function returning a failure.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.DeviceGetSerialnum(K4AdotNet.NativeHandles.DeviceHandle,System.Byte[],System.UIntPtr@)">
            <summary>Get the Azure Kinect device serial number.</summary>
            <param name="deviceHandle">Handle obtained by <see cref="M:K4AdotNet.Sensor.NativeApi.DeviceOpen(System.UInt32,K4AdotNet.NativeHandles.DeviceHandle@)"/>.</param>
            <param name="serialNumber">
            Location to write the serial number to. If the function returns <see cref="F:K4AdotNet.NativeCallResults.BufferResult.Succeeded"/>,
            this will be a NULL-terminated string of ASCII characters.
            If this input is <see langword="null"/>, <paramref name="serialNumberSize"/> will still be updated to return
            the size of the buffer needed to store the string.
            </param>
            <param name="serialNumberSize">
            On input, the size of the <paramref name="serialNumber"/> buffer if that pointer is not <see langword="null"/>.
            On output, this value is set to the actual number of bytes in the serial number (including the null terminator).
            </param>
            <returns>
            A return of <see cref="F:K4AdotNet.NativeCallResults.BufferResult.Succeeded"/> means that the <paramref name="serialNumber"/> has been filled in.
            If the buffer is too small the function returns <see cref="F:K4AdotNet.NativeCallResults.BufferResult.TooSmall"/> and the size of the serial number is
            returned in the <paramref name="serialNumberSize"/> parameter.
            All other failures return <see cref="F:K4AdotNet.NativeCallResults.BufferResult.Failed"/>.
            </returns>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.DeviceGetVersion(K4AdotNet.NativeHandles.DeviceHandle,K4AdotNet.Sensor.HardwareVersion@)">
            <summary>Get the version numbers of the device's subsystems.</summary>
            <param name="deviceHandle">Handle obtained by <see cref="M:K4AdotNet.Sensor.NativeApi.DeviceOpen(System.UInt32,K4AdotNet.NativeHandles.DeviceHandle@)"/>.</param>
            <param name="version">Output parameter which on success will return version info.</param>
            <returns>
            A return of <see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> means that the version structure has been filled in.
            All other failures return <see cref="F:K4AdotNet.NativeCallResults.Result.Failed"/>.
            </returns>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.DeviceGetColorControlCapabilities(K4AdotNet.NativeHandles.DeviceHandle,K4AdotNet.Sensor.ColorControlCommand,System.Boolean@,System.Int32@,System.Int32@,System.Int32@,System.Int32@,K4AdotNet.Sensor.ColorControlMode@)">
            <summary>Get the Azure Kinect color sensor control capabilities.</summary>
            <param name="deviceHandle">Handle obtained by <see cref="M:K4AdotNet.Sensor.NativeApi.DeviceOpen(System.UInt32,K4AdotNet.NativeHandles.DeviceHandle@)"/>.</param>
            <param name="command">Color sensor control command.</param>
            <param name="supportsAuto">Output: whether the color sensor's control support auto mode or not. <see langword="true"/> if it supports auto mode, otherwise <see langword="false"/>.</param>
            <param name="minValue">Output: the color sensor's control minimum value of <paramref name="command"/>.</param>
            <param name="maxValue">Output: the color sensor's control maximum value of <paramref name="command"/>.</param>
            <param name="stepValue">Output: the color sensor's control step value of <paramref name="command"/>.</param>
            <param name="defaultValue">Output: the color sensor's control default value of <paramref name="command"/>.</param>
            <param name="defaultMode">Output: the color sensor's control default mode of <paramref name="command"/>.</param>
            <returns><see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> if the value was successfully returned, <see cref="F:K4AdotNet.NativeCallResults.Result.Failed"/> if an error occurred</returns>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.DeviceGetColorControl(K4AdotNet.NativeHandles.DeviceHandle,K4AdotNet.Sensor.ColorControlCommand,K4AdotNet.Sensor.ColorControlMode@,System.Int32@)">
            <summary>Get the Azure Kinect color sensor control value.</summary>
            <param name="deviceHandle">Handle obtained by <see cref="M:K4AdotNet.Sensor.NativeApi.DeviceOpen(System.UInt32,K4AdotNet.NativeHandles.DeviceHandle@)"/>.</param>
            <param name="command">Color sensor control command.</param>
            <param name="mode">This mode represents whether the command is in automatic or manual mode.</param>
            <param name="value">This value is always written, but is only valid when the <paramref name="mode"/> returned is <see cref="F:K4AdotNet.Sensor.ColorControlMode.Manual"/> for the current <paramref name="command"/>.</param>
            <returns><see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> if the value was successfully returned, <see cref="F:K4AdotNet.NativeCallResults.Result.Failed"/> if an error occurred.</returns>
            <remarks>
            Each control command may be set to manual or automatic. See the definition of <see cref="T:K4AdotNet.Sensor.ColorControlCommand"/> on
            how to interpret the <paramref name="value"/> for each command.
            
            Some control commands are only supported in manual mode. When a command is in automatic mode, the <paramref name="value"/> for
            that command is not valid.
            
            Control values set on a device are reset only when the device is power cycled. The device will retain the
            settings even if the <paramref name="deviceHandle"/> is closed or the application is restarted.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.DeviceSetColorControl(K4AdotNet.NativeHandles.DeviceHandle,K4AdotNet.Sensor.ColorControlCommand,K4AdotNet.Sensor.ColorControlMode,System.Int32)">
            <summary>Set the Azure Kinect color sensor control value.</summary>
            <param name="deviceHandle">Handle obtained by <see cref="M:K4AdotNet.Sensor.NativeApi.DeviceOpen(System.UInt32,K4AdotNet.NativeHandles.DeviceHandle@)"/>.</param>
            <param name="command">Color sensor control command.</param>
            <param name="mode">Color sensor control mode to set. This mode represents whether the command is in automatic or manual mode.</param>
            <param name="value">
            Value to set the color sensor's control to. The value is only valid if <paramref name="mode"/>
            is set to <see cref="F:K4AdotNet.Sensor.ColorControlMode.Manual"/>, and is otherwise ignored.
            </param>
            <returns><see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> if the value was successfully set, <see cref="F:K4AdotNet.NativeCallResults.Result.Failed"/> if an error occurred</returns>
            <remarks>
            Each control command may be set to manual or automatic. See the definition of <see cref="T:K4AdotNet.Sensor.ColorControlCommand"/> on how
            to interpret the <paramref name="value"/> for each command.
            
            Some control commands are only supported in manual mode. When a command is in automatic mode, the <paramref name="value"/> for that
            command is not valid.
            
            Control values set on a device are reset only when the device is power cycled. The device will retain the settings
            even if the device is closed or the application is restarted.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.DeviceGetRawCalibration(K4AdotNet.NativeHandles.DeviceHandle,System.Byte[],System.UIntPtr@)">
            <summary>Get the raw calibration blob for the entire Azure Kinect device.</summary>
            <param name="deviceHandle">Handle obtained by <see cref="M:K4AdotNet.Sensor.NativeApi.DeviceOpen(System.UInt32,K4AdotNet.NativeHandles.DeviceHandle@)"/>.</param>
            <param name="data">
            Location to write the calibration data to. This field may optionally be set to <see langword="null"/> for the caller to query for
            the needed data size.
            </param>
            <param name="dataSize">
            On passing <paramref name="dataSize"/> into the function this variable represents the available size of the <paramref name="data"/>
            buffer. On return this variable is updated with the amount of data actually written to the buffer, or the size
            required to store the calibration buffer if <paramref name="data"/> is <see langword="null"/>.
            </param>
            <returns>
            <see cref="F:K4AdotNet.NativeCallResults.BufferResult.Succeeded"/> if <paramref name="data"/> was successfully written.
            If <paramref name="dataSize"/> points to a buffer size that is
            too small to hold the output or <paramref name="data"/> data is <see langword="null"/>, <see cref="F:K4AdotNet.NativeCallResults.BufferResult.TooSmall"/> is returned
            and <paramref name="dataSize"/> is updated to contain the minimum buffer size needed to capture the calibration data.
            </returns>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.DeviceGetCalibration(K4AdotNet.NativeHandles.DeviceHandle,K4AdotNet.Sensor.DepthMode,K4AdotNet.Sensor.ColorResolution,K4AdotNet.Sensor.Calibration@)">
            <summary>Get the camera calibration for the entire Azure Kinect device.</summary>
            <param name="deviceHandle">Handle obtained by <see cref="M:K4AdotNet.Sensor.NativeApi.DeviceOpen(System.UInt32,K4AdotNet.NativeHandles.DeviceHandle@)"/>.</param>
            <param name="depthMode">Mode in which depth camera is operated.</param>
            <param name="colorResolution">Resolution in which color camera is operated.</param>
            <param name="calibration">Output: calibration data.</param>
            <returns><see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> if <paramref name="calibration"/> was successfully written. <see cref="F:K4AdotNet.NativeCallResults.Result.Failed"/> otherwise.</returns>
            <remarks>
            The <paramref name="calibration"/> represents the data needed to transform between the camera views and may be
            different for each operating <paramref name="depthMode"/> and <paramref name="colorResolution"/> the device is configured to operate in.
            
            The <paramref name="calibration"/> output is used as input to all calibration and transformation functions.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.DeviceGetSyncJack(K4AdotNet.NativeHandles.DeviceHandle,System.Boolean@,System.Boolean@)">
            <summary>Get the device jack status for the synchronization in and synchronization out connectors.</summary>
            <param name="deviceHandle">Handle obtained by <see cref="M:K4AdotNet.Sensor.NativeApi.DeviceOpen(System.UInt32,K4AdotNet.NativeHandles.DeviceHandle@)"/>.</param>
            <param name="syncInJackConnected">Upon successful return this value will be set to true if a cable is connected to this sync in jack.</param>
            <param name="syncOutJackConnected">Upon successful return this value will be set to true if a cable is connected to this sync out jack.</param>
            <returns><see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> if the connector status was successfully read.</returns>
            <remarks>
            If <paramref name="syncOutJackConnected"/> is <see langword="true"/> then <see cref="F:K4AdotNet.Sensor.DeviceConfiguration.WiredSyncMode"/> mode can be set to
            <see cref="F:K4AdotNet.Sensor.WiredSyncMode.Standalone"/> or <see cref="F:K4AdotNet.Sensor.WiredSyncMode.Master"/>. If <paramref name="syncInJackConnected"/> is <see langword="true"/> then
            <see cref="F:K4AdotNet.Sensor.DeviceConfiguration.WiredSyncMode"/> mode can be set to <see cref="F:K4AdotNet.Sensor.WiredSyncMode.Standalone"/> or <see cref="F:K4AdotNet.Sensor.WiredSyncMode.Subordinate"/>.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.CalibrationGetFromRaw(System.Byte[],System.UIntPtr,K4AdotNet.Sensor.DepthMode,K4AdotNet.Sensor.ColorResolution,K4AdotNet.Sensor.Calibration@)">
            <summary>Get the camera calibration for a device from a raw calibration blob.</summary>
            <param name="rawCalibration">Raw calibration blob obtained from a device or recording. The raw calibration must be NULL terminated.</param>
            <param name="rawCalibrationSize">The size, in bytes, of <paramref name="rawCalibration"/> including the NULL termination.</param>
            <param name="depthMode">Mode in which depth camera is operated.</param>
            <param name="colorResolution">Resolution in which color camera is operated.</param>
            <param name="calibration">Result: calibration data</param>
            <returns><see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> if <paramref name="calibration"/> was successfully written. <see cref="F:K4AdotNet.NativeCallResults.Result.Failed"/> otherwise.</returns>
            <remarks>
            The <paramref name="calibration"/> represents the data needed to transform between the camera views and is
            different for each operating <paramref name="depthMode"/> and <paramref name="colorResolution"/> the device is configured to operate in.
            
            The <paramref name="calibration"/> output is used as input to all transformation functions.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.Calibration3DTo3D(K4AdotNet.Sensor.Calibration@,K4AdotNet.Float3@,K4AdotNet.Sensor.CalibrationGeometry,K4AdotNet.Sensor.CalibrationGeometry,K4AdotNet.Float3@)">
            <summary>Transform a 3D point of a source coordinate system into a 3D point of the target coordinate system.</summary>
            <param name="calibration">Camera calibration data.</param>
            <param name="sourcePoint3DMm">The 3D coordinates in millimeters representing a point in <paramref name="sourceCamera"/>.</param>
            <param name="sourceCamera">The current camera.</param>
            <param name="targetCamera">The target camera.</param>
            <param name="targetPoint3DMm">Output: the new 3D coordinates of the input point in the coordinate space <paramref name="targetCamera"/> in millimeters.</param>
            <returns>
            <see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> if <paramref name="targetPoint3DMm"/> was successfully written.
            <see cref="F:K4AdotNet.NativeCallResults.Result.Failed"/> if <paramref name="calibration"/> contained invalid transformation parameters.
            </returns>
            <remarks>
            This function is used to transform 3D points between depth and color camera coordinate systems. The function uses the
            extrinsic camera calibration. It computes the output via multiplication with a precomputed matrix encoding a 3D
            rotation and a 3D translation. If <paramref name="sourceCamera"/> and <paramref name="targetCamera"/> are the same, then <paramref name="targetPoint3DMm"/> will
            be identical to <paramref name="sourcePoint3DMm"/>.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.Calibration2DTo3D(K4AdotNet.Sensor.Calibration@,K4AdotNet.Float2@,System.Single,K4AdotNet.Sensor.CalibrationGeometry,K4AdotNet.Sensor.CalibrationGeometry,K4AdotNet.Float3@,System.Boolean@)">
            <summary>
            Transform a 2D pixel coordinate with an associated depth value of the source camera
            into a 3D point of the target coordinate system.
            </summary>
            <param name="calibration">Camera calibration data.</param>
            <param name="sourcePoint2D">The 2D pixel in <paramref name="sourceCamera"/> coordinates.</param>
            <param name="sourceDepthMm">The depth of <paramref name="sourcePoint2D"/> in millimeters.</param>
            <param name="sourceCamera">The current camera.</param>
            <param name="targetCamera">The target camera.</param>
            <param name="targetPoint3DMm">Output: the 3D coordinates of the input pixel in the coordinate system of <paramref name="targetCamera"/> in millimeters.</param>
            <param name="valid">
            The output parameter returns a value of <see langword="true"/> if the <paramref name="sourcePoint2D"/> is a valid coordinate,
            and will return <see langword="false"/> if the coordinate is not valid in the calibration model.
            </param>
            <returns>
            <see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> if <paramref name="targetPoint3DMm"/> was successfully written.
            <see cref="F:K4AdotNet.NativeCallResults.Result.Failed"/> if <paramref name="calibration"/>
            contained invalid transformation parameters.
            If the function returns <see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/>, but <paramref name="valid"/> valid is <see langword="false"/>,
            the transformation was computed, but the results in <paramref name="targetPoint3DMm"/> are outside of the range of valid
            calibration and should be ignored.
            </returns>
            <remarks>
            This function applies the intrinsic calibration of <paramref name="sourceCamera"/> to compute the 3D ray from the focal point of the
            camera through pixel <paramref name="sourcePoint2D"/>.The 3D point on this ray is then found using <paramref name="sourceDepthMm"/>. If
            <paramref name="targetCamera"/> is different from <paramref name="sourceCamera"/>, the 3D point is transformed to <paramref name="targetCamera"/> using
            <see cref="M:K4AdotNet.Sensor.NativeApi.Calibration3DTo3D(K4AdotNet.Sensor.Calibration@,K4AdotNet.Float3@,K4AdotNet.Sensor.CalibrationGeometry,K4AdotNet.Sensor.CalibrationGeometry,K4AdotNet.Float3@)"/>.
            In practice, <paramref name="sourceCamera"/> and <paramref name="targetCamera"/> will often be identical. In this
            case, no 3D to 3D transformation is applied.
            
            If <paramref name="sourcePoint2D"/> is not considered as valid pixel coordinate
            according to the intrinsic camera model, <paramref name="valid"/> is set to <see langword="false"/>.
            If it is valid, <paramref name="valid"/> valid will be set to <see langword="true"/>. The user
            should not use the value of <paramref name="targetPoint3DMm"/> if <paramref name="valid"/> was set to <see langword="false"/>.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.Calibration3DTo2D(K4AdotNet.Sensor.Calibration@,K4AdotNet.Float3@,K4AdotNet.Sensor.CalibrationGeometry,K4AdotNet.Sensor.CalibrationGeometry,K4AdotNet.Float2@,System.Boolean@)">
            <summary>Transform a 3D point of a source coordinate system into a 2D pixel coordinate of the target camera.</summary>
            <param name="calibration">Camera calibration data.</param>
            <param name="sourcePoint3DMm">The 3D coordinates in millimeters representing a point in <paramref name="sourceCamera"/>.</param>
            <param name="sourceCamera">The current camera.</param>
            <param name="targetCamera">The target camera.</param>
            <param name="targetPoint2D">Output: the 2D pixel in <paramref name="targetCamera"/> coordinates.</param>
            <param name="valid">
            The output parameter returns <see langword="true"/> if the <paramref name="sourcePoint3DMm"/> is a valid coordinate in the <paramref name="targetCamera"/>
            coordinate system, and will return <see langword="false"/> if the coordinate is not valid in the calibration model.
            </param>
            <returns>
            <see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> if <paramref name="targetPoint2D"/> was successfully written.
            <see cref="F:K4AdotNet.NativeCallResults.Result.Failed"/> if <paramref name="calibration"/> contained invalid transformation parameters.
            If the function returns <see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/>, but <paramref name="valid"/> is <see langword="false"/>,
            the transformation was computed, but the results in <paramref name="targetPoint2D"/> are outside of the range of valid calibration
            and should be ignored.
            </returns>
            <remarks>
            If <paramref name="targetCamera"/> is different from <paramref name="sourceCamera"/>, <paramref name="sourcePoint3DMm"/> is transformed
            to <paramref name="targetCamera"/> using <see cref="M:K4AdotNet.Sensor.NativeApi.Calibration3DTo3D(K4AdotNet.Sensor.Calibration@,K4AdotNet.Float3@,K4AdotNet.Sensor.CalibrationGeometry,K4AdotNet.Sensor.CalibrationGeometry,K4AdotNet.Float3@)"/>.
            In practice, <paramref name="sourceCamera"/> and <paramref name="targetCamera"/> will often be identical.
            In this case, no 3D to 3D transformation is applied. The 3D point in the coordinate system of <paramref name="targetCamera"/> is then
            projected onto the image plane using the intrinsic calibration of <paramref name="targetCamera"/>.
            
            If <paramref name="sourcePoint3DMm"/> does not map to a valid 2D coordinate in the <paramref name="targetCamera"/> coordinate system,
            <paramref name="valid"/> is set to <see langword="false"/>. If it is valid, <paramref name="valid"/> will be set to <see langword="true"/>.
            The user should not use the value of <paramref name="targetPoint2D"/> if <paramref name="valid"/> was set to <see langword="false"/>.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.Calibration2DTo2D(K4AdotNet.Sensor.Calibration@,K4AdotNet.Float2@,System.Single,K4AdotNet.Sensor.CalibrationGeometry,K4AdotNet.Sensor.CalibrationGeometry,K4AdotNet.Float2@,System.Boolean@)">
            <summary>
            Transform a 2D pixel coordinate with an associated depth value of the source camera into a 2D pixel coordinate of the target camera.
            </summary>
            <param name="calibration">Camera calibration data.</param>
            <param name="sourcePoint2D">The 2D pixel in <paramref name="sourceCamera"/> coordinates.</param>
            <param name="sourceDepthMm">The depth of <paramref name="sourcePoint2D"/> in millimeters.</param>
            <param name="sourceCamera">The current camera.</param>
            <param name="targetCamera">The target camera.</param>
            <param name="targetPoint2D">Output: the 2D pixel in <paramref name="targetCamera"/> coordinates.</param>
            <param name="valid">
            The output parameter returns <see langword="true"/> if the <paramref name="sourcePoint2D"/> is a valid coordinate in the <paramref name="targetCamera"/>
            coordinate system, and will return <see langword="false"/> if the coordinate is not valid in the calibration model.
            </param>
            <returns>
            <see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> if <paramref name="targetPoint2D"/> was successfully written.
            <see cref="F:K4AdotNet.NativeCallResults.Result.Failed"/> if <paramref name="calibration"/> contained invalid transformation parameters.
            If the function returns <see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/>, but <paramref name="valid"/> valid is <see langword="false"/>,
            the transformation was computed, but the results in <paramref name="targetPoint2D"/> are outside of the range of valid calibration
            and should be ignored.
            </returns>
            <remarks>
            This function maps a pixel between the coordinate systems of the depth and color cameras. It is equivalent to calling
            <see cref="M:K4AdotNet.Sensor.NativeApi.Calibration2DTo3D(K4AdotNet.Sensor.Calibration@,K4AdotNet.Float2@,System.Single,K4AdotNet.Sensor.CalibrationGeometry,K4AdotNet.Sensor.CalibrationGeometry,K4AdotNet.Float3@,System.Boolean@)"/> to compute the 3D point corresponding to <paramref name="sourcePoint2D"/> and then using
            <see cref="M:K4AdotNet.Sensor.NativeApi.Calibration3DTo2D(K4AdotNet.Sensor.Calibration@,K4AdotNet.Float3@,K4AdotNet.Sensor.CalibrationGeometry,K4AdotNet.Sensor.CalibrationGeometry,K4AdotNet.Float2@,System.Boolean@)"/> to map the 3D point into the coordinate system of the <paramref name="targetCamera"/>.
            
            If <paramref name="sourceCamera"/> and <paramref name="targetCamera"/> are identical, the function immediately sets <paramref name="targetPoint2D"/> to
            <paramref name="sourcePoint2D"/> and returns without computing any transformations.
            
            If <paramref name="sourcePoint2D"/> does not map to a valid 2D coordinate in the <paramref name="targetCamera"/> coordinate system,
            <paramref name="valid"/> is set to <see langword="false"/>. If it is valid, <paramref name="valid"/> will be set to <see langword="true"/>.
            The user should not use the value of <paramref name="targetPoint2D"/> if <paramref name="valid"/> was set to 0.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.TransformationCreate(K4AdotNet.Sensor.Calibration@)">
            <summary>Get handle to transformation.</summary>
            <param name="calibration">Camera calibration data.</param>
            <returns>A transformation handle. An invalid handle is returned if creation fails.</returns>
            <remarks>
            The transformation handle is used to transform images from the coordinate system of one camera into the other. Each
            transformation handle requires some pre-computed resources to be allocated, which are retained until the handle is
            destroyed.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.TransformationDepthImageToColorCamera(K4AdotNet.NativeHandles.TransformationHandle,K4AdotNet.NativeHandles.ImageHandle,K4AdotNet.NativeHandles.ImageHandle)">
            <summary>Transforms the depth map into the geometry of the color camera.</summary>
            <param name="transformationHandle">Transformation handle.</param>
            <param name="depthImage">Handle to input depth image.</param>
            <param name="transformedDepthImage">Handle to output transformed depth image.</param>
            <returns>
            <see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> if <paramref name="transformedDepthImage"/> was successfully written
            and <see cref="F:K4AdotNet.NativeCallResults.Result.Failed"/> otherwise.
            </returns>
            <remarks>
            This produces a depth image for which each pixel matches the corresponding pixel coordinates of the color camera.
            
            <paramref name="depthImage"/> and <paramref name="transformedDepthImage"/> must be of format <see cref="F:K4AdotNet.Sensor.ImageFormat.Depth16"/>.
            
            <paramref name="transformedDepthImage"/> must have a width and height matching the width and height of the color camera in the mode
            specified by the <see cref="T:K4AdotNet.Sensor.Calibration"/> used to create the <paramref name="transformationHandle"/> with <see cref="M:K4AdotNet.Sensor.NativeApi.TransformationCreate(K4AdotNet.Sensor.Calibration@)"/>.
            
            The contents <paramref name="transformedDepthImage"/> will be filled with the depth values derived from <paramref name="depthImage"/> in the color
            camera's coordinate space.
            
            <paramref name="transformedDepthImage"/> should be created by the caller using <see cref="M:K4AdotNet.Sensor.NativeApi.ImageCreate(K4AdotNet.Sensor.ImageFormat,System.Int32,System.Int32,System.Int32,K4AdotNet.NativeHandles.ImageHandle@)"/>
            or <see cref="M:K4AdotNet.Sensor.NativeApi.ImageCreateFromBuffer(K4AdotNet.Sensor.ImageFormat,System.Int32,System.Int32,System.Int32,System.IntPtr,System.UIntPtr,K4AdotNet.Sensor.NativeApi.MemoryDestroyCallback,System.IntPtr,K4AdotNet.NativeHandles.ImageHandle@)"/>.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.TransformationColorImageToDepthCamera(K4AdotNet.NativeHandles.TransformationHandle,K4AdotNet.NativeHandles.ImageHandle,K4AdotNet.NativeHandles.ImageHandle,K4AdotNet.NativeHandles.ImageHandle)">
            <summary>Transforms a color image into the geometry of the depth camera.</summary>
            <param name="transformationHandle">Transformation handle.</param>
            <param name="depthImage">Handle to input depth image.</param>
            <param name="colorImage">Handle to input color image.</param>
            <param name="transformedColorImage">Handle to output transformed color image.</param>
            <returns>
            <see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> if <paramref name="transformedColorImage"/> was successfully written
            and <see cref="F:K4AdotNet.NativeCallResults.Result.Failed"/> otherwise.
            </returns>
            <remarks>
            This produces a color image for which each pixel matches the corresponding pixel coordinates of the depth camera.
            
            <paramref name="depthImage"/> and <paramref name="colorImage"/> need to represent the same moment in time. The depth data will be applied to the
            color image to properly warp the color data to the perspective of the depth camera.
            
            <paramref name="depthImage"/> must be of type <see cref="F:K4AdotNet.Sensor.ImageFormat.Depth16"/>. <paramref name="colorImage"/> must be of format
            <see cref="F:K4AdotNet.Sensor.ImageFormat.ColorBgra32"/>.
            
            <paramref name="transformedColorImage"/> image must be of format <see cref="F:K4AdotNet.Sensor.ImageFormat.ColorBgra32"/>. <paramref name="transformedColorImage"/> must
            have the width and height of the depth camera in the mode specified by the <see cref="T:K4AdotNet.Sensor.Calibration"/> used to create
            the <paramref name="transformationHandle"/> with <see cref="M:K4AdotNet.Sensor.NativeApi.TransformationCreate(K4AdotNet.Sensor.Calibration@)"/>.
            
            <paramref name="transformedColorImage"/> should be created by the caller using <see cref="M:K4AdotNet.Sensor.NativeApi.ImageCreate(K4AdotNet.Sensor.ImageFormat,System.Int32,System.Int32,System.Int32,K4AdotNet.NativeHandles.ImageHandle@)"/>
            or <see cref="M:K4AdotNet.Sensor.NativeApi.ImageCreateFromBuffer(K4AdotNet.Sensor.ImageFormat,System.Int32,System.Int32,System.Int32,System.IntPtr,System.UIntPtr,K4AdotNet.Sensor.NativeApi.MemoryDestroyCallback,System.IntPtr,K4AdotNet.NativeHandles.ImageHandle@)"/>.
            </remarks>
        </member>
        <member name="M:K4AdotNet.Sensor.NativeApi.TransformationDepthImageToPointCloud(K4AdotNet.NativeHandles.TransformationHandle,K4AdotNet.NativeHandles.ImageHandle,K4AdotNet.Sensor.CalibrationGeometry,K4AdotNet.NativeHandles.ImageHandle)">
            <summary>Transforms the depth image into 3 planar images representing X, Y and Z-coordinates of corresponding 3D points.</summary>
            <param name="transformationHandle">Transformation handle.</param>
            <param name="depthImage">Handle to input depth image.</param>
            <param name="camera">Geometry in which depth map was computed.</param>
            <param name="xyzImage">Handle to output xyz image.</param>
            <returns>
            <see cref="F:K4AdotNet.NativeCallResults.Result.Succeeded"/> if <paramref name="xyzImage"/> was successfully written
            and <see cref="F:K4AdotNet.NativeCallResults.Result.Failed"/> otherwise.
            </returns>
            <remarks>
            <paramref name="depthImage"/> must be of format <see cref="F:K4AdotNet.Sensor.ImageFormat.Depth16"/>.
            
            The <paramref name="camera"/> parameter tells the function what the perspective of the <paramref name="depthImage"/> is.
            If the <paramref name="depthImage"/> was captured directly from the depth camera, the value should be <see cref="F:K4AdotNet.Sensor.CalibrationGeometry.Depth"/>.
            If the <paramref name="depthImage"/> is the result of a transformation into the color camera's coordinate space using
            <see cref="M:K4AdotNet.Sensor.NativeApi.TransformationDepthImageToColorCamera(K4AdotNet.NativeHandles.TransformationHandle,K4AdotNet.NativeHandles.ImageHandle,K4AdotNet.NativeHandles.ImageHandle)"/>,
            the value should be <see cref="F:K4AdotNet.Sensor.CalibrationGeometry.Color"/>.
            
            The format of <paramref name="xyzImage"/> must be <see cref="F:K4AdotNet.Sensor.ImageFormat.Custom"/>. The width and height of <paramref name="xyzImage"/> must match the
            width and height of <paramref name="depthImage"/>. <paramref name="xyzImage"/> must have a stride in bytes of at least 6 times its width in pixels.
            
            Each pixel of the <paramref name="xyzImage"/> consists of three <see cref="T:System.Int16"/> values, totaling 6 bytes. The three <see cref="T:System.Int16"/> values are the
            X, Y, and Z values of the point.
            
            <paramref name="xyzImage"/> should be created by the caller using <see cref="M:K4AdotNet.Sensor.NativeApi.ImageCreate(K4AdotNet.Sensor.ImageFormat,System.Int32,System.Int32,System.Int32,K4AdotNet.NativeHandles.ImageHandle@)"/>
            or <see cref="M:K4AdotNet.Sensor.NativeApi.ImageCreateFromBuffer(K4AdotNet.Sensor.ImageFormat,System.Int32,System.Int32,System.Int32,System.IntPtr,System.UIntPtr,K4AdotNet.Sensor.NativeApi.MemoryDestroyCallback,System.IntPtr,K4AdotNet.NativeHandles.ImageHandle@)"/>.
            </remarks>
        </member>
        <member name="T:K4AdotNet.Sensor.WiredSyncMode">
            <summary>Synchronization mode when connecting two or more devices together.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.WiredSyncMode.Standalone">
            <summary>Neither 'Sync In' or 'Sync Out' connections are used.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.WiredSyncMode.Master">
            <summary>The 'Sync Out' jack is enabled and synchronization data it driven out the connected wire.</summary>
        </member>
        <member name="F:K4AdotNet.Sensor.WiredSyncMode.Subordinate">
            <summary>
            The 'Sync In' jack is used for synchronization and 'Sync Out' is driven for the
            next device in the chain. 'Sync Out' is a mirror of 'Sync In' for this mode.
            </summary>
        </member>
    </members>
</doc>
